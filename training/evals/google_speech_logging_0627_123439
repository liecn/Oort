/mnt/home/lichenni/anaconda3/envs/oort/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.
Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.
  from numba.decorators import jit as optional_jit
/mnt/home/lichenni/anaconda3/envs/oort/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.
Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.
  from numba.decorators import jit as optional_jit
2021-06-27:12:35:33,902 INFO     [param_server.py:11] End up with cuda device tensor([0.0369], device='cuda:0')
2021-06-27:12:35:35,624 INFO     [param_server.py:525] ====Start to initialize dataset
2021-06-27:12:35:37,553 INFO     [flLibs.py:59] ====Initialize the model
2021-06-27:12:35:43,281 INFO     [flLibs.py:137] ====Load model successfully

2021-06-27:12:35:46,15 INFO     [learner.py:13] End up with cuda device tensor([0.8092], device='cuda:1')
2021-06-27:12:35:46,29 INFO     [learner.py:39] ===== Experiment start on : dev-amd20-v100=====
2021-06-27:12:35:46,469 INFO     [learner.py:675] ====Start to initialize dataset
2021-06-27:12:35:49,12 INFO     [flLibs.py:59] ====Initialize the model
2021-06-27:12:35:51,415 INFO     [learner.py:698] ==== Starting training data partitioner =====
2021-06-27:12:36:03,675 INFO     [divide_data.py:94] ====Initiating DataPartitioner takes 0.050124406814575195 s

2021-06-27:12:36:03,682 INFO     [learner.py:701] ==== Finished training data partitioner =====
2021-06-27:12:36:12,40 INFO     [param_server.py:77] ====Info of all feasible clients {'total_feasible_clients': 1525, 'total_length': 53206}
2021-06-27:12:36:13,800 INFO     [param_server.py:138] ====PS: get in run()
2021-06-27:12:36:13,799 INFO     [learner.py:714] ==== Starting testing data partitioner =====
2021-06-27:12:36:13,803 INFO     [divide_data.py:94] ====Initiating DataPartitioner takes 0.0012905597686767578 s

2021-06-27:12:36:13,805 INFO     [learner.py:716] ==== Finished testing data partitioner =====
2021-06-27:12:36:13,812 INFO     [divide_data.py:349] ========= Start of Random Partition =========

2021-06-27:12:36:13,831 INFO     [divide_data.py:470] Raw class per worker is : array([[ 74.,  70.,  93.,  90.,  71.,  98., 112.,  61., 101., 105.,  73.,
         92.,  86.,  57.,  49., 102.,  47.,  39.,  93.,  75.]])

2021-06-27:12:36:13,833 INFO     [divide_data.py:471] ========= End of Class/Worker =========

====Worker: init_myprocesses
2021-06-27:12:36:15,755 INFO     [learner.py:424] ====Worker: Start running
Begin!
2021-06-27:12:36:15,841 INFO     [learner.py:460] 
Namespace(adam_epsilon=1e-08, backend='nccl', batch_size=16, bidirectional=True, blacklist_max_len=0.3, blacklist_rounds=-1, block_size=64, cache_dir=None, capacity_bin=True, clf_block_size=100, client_path='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/data/device_info/client_profile.pkl', clip_bound=0.98, clock_factor=6.092057761732853, conf_path='~/dataset/', config_name=None, cut_off_util=0.4, data_dir='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/google_speech', data_mapfile='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/google_speech/clientDataMap', data_set='google_speech', decay_epoch=15.0, decay_factor=0.95, display_step=20, do_eval=False, do_train=False, dump_epoch=1000, duplicate_data=1, enable_importance=False, enforce_random=False, epochs=10, eval_all_checkpoints=False, eval_data_file='', eval_interval=2, eval_interval_prior=9999999, evaluate_during_training=False, exploration_alpha=0.3, exploration_decay=0.95, exploration_factor=0.9, exploration_min=0.2, filter_class=0, filter_less=17, filter_more=100000.0, finetune=False, fixed_clients=False, force_read=False, forward_pass=False, fp16=False, fp16_opt_level='O1', full_gradient_interval=20, gpu_device=1, gradient_accumulation_steps=1, gradient_policy='yogi', hetero_allocation='1.0-1.0-1.0-1.0-1.0-1.0', heterogeneity=1.0, hidden_layers=7, hidden_size=256, input_dim=0, is_even_avg=True, job_name='google_speech', labels_path='labels.json', learners='1', learning_rate=0.04, line_by_line=False, load_model=True, load_perf_epoch=41, load_time_stamp='0627_122125', local_rank=-1, log_path='/mnt/home/lichenni/projects/Oort/training/evals', logging_steps=500, loss_decay=0.2, malicious_clients=0, manager_port=4688, max_grad_norm=1.0, max_iter_store=100, max_steps=-1, min_learning_rate=0.0001, mlm=True, mlm_probability=0.1, model='resnet34', model_avg=True, model_name_or_path=None, model_path=None, model_size=65536, model_type='', no_cuda=False, noise_dir=None, noise_factor=0, noise_max=0.5, noise_min=0.0, noise_prob=0.4, num_class=20, num_classes=20, num_loaders=2, num_train_epochs=1.0, output_dim=0, output_dir=None, overcommit=1.1, overwrite_cache=False, overwrite_output_dir=False, pacer_delta=30.0, pacer_step=20, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, proxy_avg=False, proxy_mu=0.1, ps_ip='dev-amd20-v100', ps_port='41806', read_models_path=False, release_cache=False, resampling_interval=1, rnn_type='lstm', round_penalty=2.0, round_threshold=40.0, run_all=False, sample_mode='random', sample_rate=16000, sample_seed=233, sample_window=5.0, sampler_path=None, save_path='./', save_steps=500, save_total_limit=None, score_mode='loss', seed=42, sequential='0', server_ip='', server_port='', should_continue=False, single_sim=0, skip_partition=False, sleep_up=0, spec_augment=False, speed_volume_perturb=False, stale_threshold=0, task='speech', test_bsz=256, test_interval=20, test_manifest='data/test_manifest.csv', test_only=False, test_ratio=1.0, test_train_data=False, this_rank=1, threads=4, time_stamp='0627_123439', timeout=9999999, to_device='cuda', tokenizer_name=None, total_worker=100, train_data_file='', train_manifest='data/train_manifest.csv', upload_epoch=10, user_trace=None, validate_interval=999999, vocab_tag_size=500, vocab_token_size=10000, warmup_steps=0, weight_decay=0.0, window='hamming', window_size=0.02, window_stride=0.01, yogi_beta=0.999, yogi_beta2=-1, yogi_eta=0.005, yogi_tau=0.001, zipf_alpha='5')

2021-06-27:12:36:16,259 INFO     [learner.py:155] Start to run client 1 on rank 1...
2021-06-27:12:36:42,155 INFO     [learner.py:418] Completed to run client 1
2021-06-27:12:36:44,27 INFO     [learner.py:581] ====Pushing takes 0.4547843933105469 s
2021-06-27:12:36:50,804 INFO     [param_server.py:229] ====Start to merge models
2021-06-27:12:37:16,295 INFO     [param_server.py:287] ====Done handling rank 1, with ratio 0.14285714285714285, now collected 1 clients
2021-06-27:12:37:36,507 INFO     [param_server.py:316] ====After aggregation in epoch: 0, virtual_clock: 0.0, top_1: : 0.0 % (0.0), top_5: : 0.0 % (0.0), test loss: 0.0, test len: 1.0
