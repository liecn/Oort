/mnt/home/lichenni/anaconda3/envs/oort/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.
Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.
  from numba.decorators import jit as optional_jit
2021-06-19:16:28:01,759 INFO     [param_server.py:11] End up with cuda device tensor([0.7230], device='cuda:0')
2021-06-19:16:28:02,164 INFO     [param_server.py:508] ====Start to initialize dataset
2021-06-19:16:28:02,167 INFO     [flLibs.py:62] ====Initialize the model
/mnt/home/lichenni/anaconda3/envs/oort/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.
Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.
  from numba.decorators import jit as optional_jit
2021-06-19:16:28:08,48 INFO     [learner.py:10] End up with cuda device tensor([0.7449], device='cuda:1')
2021-06-19:16:28:08,51 INFO     [learner.py:35] ===== Experiment start on : lac-348=====
2021-06-19:16:28:08,455 INFO     [learner.py:644] ====Start to initialize dataset
2021-06-19:16:28:08,457 INFO     [flLibs.py:62] ====Initialize the model
2021-06-19:16:28:09,264 INFO     [learner.py:667] ==== Starting training data partitioner =====
2021-06-19:16:28:09,289 INFO     [divide_data.py:94] ====Initiating DataPartitioner takes 0.024178266525268555 s

2021-06-19:16:28:09,290 INFO     [learner.py:670] ==== Finished training data partitioner =====
/mnt/home/lichenni/anaconda3/envs/oort/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.
Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.
  from numba.decorators import jit as optional_jit
2021-06-19:16:28:37,541 INFO     [learner.py:10] End up with cuda device tensor([0.5689], device='cuda:2')
2021-06-19:16:28:37,547 INFO     [learner.py:35] ===== Experiment start on : lac-348=====
2021-06-19:16:28:37,956 INFO     [learner.py:644] ====Start to initialize dataset
2021-06-19:16:28:37,957 INFO     [flLibs.py:62] ====Initialize the model
2021-06-19:16:28:38,569 INFO     [learner.py:667] ==== Starting training data partitioner =====
2021-06-19:16:28:38,594 INFO     [divide_data.py:94] ====Initiating DataPartitioner takes 0.024425029754638672 s

2021-06-19:16:28:38,596 INFO     [learner.py:670] ==== Finished training data partitioner =====
/mnt/home/lichenni/anaconda3/envs/oort/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.
Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.
  from numba.decorators import jit as optional_jit
2021-06-19:16:29:07,600 INFO     [learner.py:10] End up with cuda device tensor([0.3858], device='cuda:3')
2021-06-19:16:29:07,605 INFO     [learner.py:35] ===== Experiment start on : lac-348=====
2021-06-19:16:29:08,10 INFO     [learner.py:644] ====Start to initialize dataset
2021-06-19:16:29:08,11 INFO     [flLibs.py:62] ====Initialize the model
2021-06-19:16:29:08,619 INFO     [learner.py:667] ==== Starting training data partitioner =====
2021-06-19:16:29:08,644 INFO     [divide_data.py:94] ====Initiating DataPartitioner takes 0.024668455123901367 s

2021-06-19:16:29:08,647 INFO     [learner.py:670] ==== Finished training data partitioner =====
/mnt/home/lichenni/anaconda3/envs/oort/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.
Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.
  from numba.decorators import jit as optional_jit
2021-06-19:16:29:37,560 INFO     [learner.py:10] End up with cuda device tensor([0.1755], device='cuda:4')
2021-06-19:16:29:37,567 INFO     [learner.py:35] ===== Experiment start on : lac-348=====
2021-06-19:16:29:37,974 INFO     [learner.py:644] ====Start to initialize dataset
2021-06-19:16:29:37,975 INFO     [flLibs.py:62] ====Initialize the model
2021-06-19:16:29:38,585 INFO     [learner.py:667] ==== Starting training data partitioner =====
2021-06-19:16:29:38,610 INFO     [divide_data.py:94] ====Initiating DataPartitioner takes 0.024272680282592773 s

2021-06-19:16:29:38,611 INFO     [learner.py:670] ==== Finished training data partitioner =====
/mnt/home/lichenni/anaconda3/envs/oort/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.
Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.
  from numba.decorators import jit as optional_jit
2021-06-19:16:30:07,530 INFO     [learner.py:10] End up with cuda device tensor([0.5806], device='cuda:5')
2021-06-19:16:30:07,536 INFO     [learner.py:35] ===== Experiment start on : lac-348=====
2021-06-19:16:30:07,946 INFO     [learner.py:644] ====Start to initialize dataset
2021-06-19:16:30:07,947 INFO     [flLibs.py:62] ====Initialize the model
2021-06-19:16:30:08,554 INFO     [learner.py:667] ==== Starting training data partitioner =====
2021-06-19:16:30:08,581 INFO     [divide_data.py:94] ====Initiating DataPartitioner takes 0.02555084228515625 s

2021-06-19:16:30:08,582 INFO     [learner.py:670] ==== Finished training data partitioner =====
/mnt/home/lichenni/anaconda3/envs/oort/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.
Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.
  from numba.decorators import jit as optional_jit
2021-06-19:16:30:37,663 INFO     [learner.py:10] End up with cuda device tensor([0.6160], device='cuda:6')
2021-06-19:16:30:37,671 INFO     [learner.py:35] ===== Experiment start on : lac-348=====
2021-06-19:16:30:38,78 INFO     [learner.py:644] ====Start to initialize dataset
2021-06-19:16:30:38,80 INFO     [flLibs.py:62] ====Initialize the model
2021-06-19:16:30:38,691 INFO     [learner.py:667] ==== Starting training data partitioner =====
2021-06-19:16:30:38,717 INFO     [divide_data.py:94] ====Initiating DataPartitioner takes 0.025141477584838867 s

2021-06-19:16:30:38,719 INFO     [learner.py:670] ==== Finished training data partitioner =====
/mnt/home/lichenni/anaconda3/envs/oort/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.
Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.
  from numba.decorators import jit as optional_jit
2021-06-19:16:31:07,748 INFO     [learner.py:10] End up with cuda device tensor([0.5168], device='cuda:7')
2021-06-19:16:31:07,753 INFO     [learner.py:35] ===== Experiment start on : lac-348=====
2021-06-19:16:31:08,158 INFO     [learner.py:644] ====Start to initialize dataset
2021-06-19:16:31:08,159 INFO     [flLibs.py:62] ====Initialize the model
2021-06-19:16:31:08,768 INFO     [learner.py:667] ==== Starting training data partitioner =====
2021-06-19:16:31:08,795 INFO     [divide_data.py:94] ====Initiating DataPartitioner takes 0.025902509689331055 s

2021-06-19:16:31:08,796 INFO     [learner.py:670] ==== Finished training data partitioner =====
2021-06-19:16:31:09,224 INFO     [param_server.py:74] ====Info of all feasible clients {'total_feasible_clients': 2187, 'total_length': 103171}
2021-06-19:16:31:11,37 INFO     [param_server.py:135] ====PS: get in run()
2021-06-19:16:31:11,76 INFO     [learner.py:683] ==== Starting testing data partitioner =====
2021-06-19:16:31:11,71 INFO     [learner.py:683] ==== Starting testing data partitioner =====
2021-06-19:16:31:11,71 INFO     [learner.py:683] ==== Starting testing data partitioner =====
2021-06-19:16:31:11,80 INFO     [divide_data.py:94] ====Initiating DataPartitioner takes 0.0006289482116699219 s

2021-06-19:16:31:11,81 INFO     [divide_data.py:94] ====Initiating DataPartitioner takes 0.0006718635559082031 s

2021-06-19:16:31:11,82 INFO     [learner.py:685] ==== Finished testing data partitioner =====
2021-06-19:16:31:11,82 INFO     [learner.py:685] ==== Finished testing data partitioner =====
2021-06-19:16:31:11,77 INFO     [learner.py:683] ==== Starting testing data partitioner =====
2021-06-19:16:31:11,77 INFO     [learner.py:683] ==== Starting testing data partitioner =====
2021-06-19:16:31:11,84 INFO     [divide_data.py:349] ========= Start of Random Partition =========

2021-06-19:16:31:11,78 INFO     [divide_data.py:94] ====Initiating DataPartitioner takes 0.0006556510925292969 s

2021-06-19:16:31:11,87 INFO     [divide_data.py:94] ====Initiating DataPartitioner takes 0.0006155967712402344 s

2021-06-19:16:31:11,93 INFO     [learner.py:685] ==== Finished testing data partitioner =====
2021-06-19:16:31:11,94 INFO     [learner.py:685] ==== Finished testing data partitioner =====
2021-06-19:16:31:11,77 INFO     [learner.py:683] ==== Starting testing data partitioner =====
2021-06-19:16:31:11,86 INFO     [divide_data.py:349] ========= Start of Random Partition =========

2021-06-19:16:31:11,88 INFO     [divide_data.py:94] ====Initiating DataPartitioner takes 0.0006279945373535156 s

2021-06-19:16:31:11,77 INFO     [learner.py:683] ==== Starting testing data partitioner =====
2021-06-19:16:31:11,105 INFO     [learner.py:685] ==== Finished testing data partitioner =====
2021-06-19:16:31:11,99 INFO     [divide_data.py:94] ====Initiating DataPartitioner takes 0.0006709098815917969 s

2021-06-19:16:31:11,96 INFO     [divide_data.py:349] ========= Start of Random Partition =========

2021-06-19:16:31:11,109 INFO     [learner.py:685] ==== Finished testing data partitioner =====
2021-06-19:16:31:11,98 INFO     [divide_data.py:349] ========= Start of Random Partition =========

2021-06-19:16:31:11,107 INFO     [divide_data.py:94] ====Initiating DataPartitioner takes 0.0006740093231201172 s

2021-06-19:16:31:11,109 INFO     [divide_data.py:349] ========= Start of Random Partition =========

2021-06-19:16:31:11,123 INFO     [learner.py:685] ==== Finished testing data partitioner =====
2021-06-19:16:31:11,117 INFO     [divide_data.py:349] ========= Start of Random Partition =========

2021-06-19:16:31:11,129 INFO     [divide_data.py:349] ========= Start of Random Partition =========

2021-06-19:16:31:11,93 INFO     [divide_data.py:470] Raw class per worker is : array([[10., 11., 17.,  8.,  8., 11., 14.,  9., 15., 17., 13., 18., 11.,
         6.,  6., 15., 13.,  4., 11., 14.,  9., 10., 11., 13., 15.,  6.,
        17., 11.,  9.,  4., 11.,  9.,  9.,  7.,  7.],
       [14., 12., 19., 13., 15., 15., 14.,  6., 16., 15., 13., 12., 10.,
         4.,  9., 12.,  4.,  6., 18., 17., 14.,  7.,  5.,  7., 12.,  6.,
         9., 11., 12.,  4., 14., 12.,  9.,  6.,  7.],
       [ 3., 11., 13., 14.,  6., 16., 13., 11., 17., 12., 16.,  9.,  9.,
         7.,  9., 17.,  5.,  2., 11., 10.,  7., 11., 12.,  6., 21., 11.,
        18., 11., 16.,  5., 13., 14.,  6.,  8.,  9.],
       [12., 10., 11., 10., 14., 13., 15., 10., 12., 16., 10., 16., 10.,
        12.,  4., 10.,  4.,  8., 12.,  4., 12.,  6., 12., 11., 13., 17.,
        10., 15.,  7.,  7., 16., 11.,  5., 12., 12.],
       [17., 10., 10., 13., 10., 17., 18.,  5., 11., 14.,  5., 11.,  9.,
         6.,  6., 22.,  6.,  3., 17., 13., 13.,  5., 13.,  6., 13., 10.,
        20., 14., 10.,  6., 14., 10.,  8.,  8.,  6.],
       [ 8., 10., 13., 10.,  9., 12., 14.,  8., 18., 19.,  9., 15., 18.,
        13.,  8., 13.,  8.,  7., 14.,  7.,  8.,  6., 13.,  6., 17.,  8.,
         6., 17., 13., 10., 18.,  8.,  6.,  4.,  6.],
       [10.,  5., 10., 22.,  9., 14., 24., 12., 12., 12.,  7., 11., 19.,
         9.,  7., 13.,  7.,  9.,  9., 10.,  8.,  9., 10.,  8.,  9., 11.,
        18., 11., 11.,  1., 14., 12.,  8.,  7., 11.]])

2021-06-19:16:31:11,105 INFO     [divide_data.py:470] Raw class per worker is : array([[10., 11., 17.,  8.,  8., 11., 14.,  9., 15., 17., 13., 18., 11.,
         6.,  6., 15., 13.,  4., 11., 14.,  9., 10., 11., 13., 15.,  6.,
        17., 11.,  9.,  4., 11.,  9.,  9.,  7.,  7.],
       [14., 12., 19., 13., 15., 15., 14.,  6., 16., 15., 13., 12., 10.,
         4.,  9., 12.,  4.,  6., 18., 17., 14.,  7.,  5.,  7., 12.,  6.,
         9., 11., 12.,  4., 14., 12.,  9.,  6.,  7.],
       [ 3., 11., 13., 14.,  6., 16., 13., 11., 17., 12., 16.,  9.,  9.,
         7.,  9., 17.,  5.,  2., 11., 10.,  7., 11., 12.,  6., 21., 11.,
        18., 11., 16.,  5., 13., 14.,  6.,  8.,  9.],
       [12., 10., 11., 10., 14., 13., 15., 10., 12., 16., 10., 16., 10.,
        12.,  4., 10.,  4.,  8., 12.,  4., 12.,  6., 12., 11., 13., 17.,
        10., 15.,  7.,  7., 16., 11.,  5., 12., 12.],
       [17., 10., 10., 13., 10., 17., 18.,  5., 11., 14.,  5., 11.,  9.,
         6.,  6., 22.,  6.,  3., 17., 13., 13.,  5., 13.,  6., 13., 10.,
        20., 14., 10.,  6., 14., 10.,  8.,  8.,  6.],
       [ 8., 10., 13., 10.,  9., 12., 14.,  8., 18., 19.,  9., 15., 18.,
        13.,  8., 13.,  8.,  7., 14.,  7.,  8.,  6., 13.,  6., 17.,  8.,
         6., 17., 13., 10., 18.,  8.,  6.,  4.,  6.],
       [10.,  5., 10., 22.,  9., 14., 24., 12., 12., 12.,  7., 11., 19.,
         9.,  7., 13.,  7.,  9.,  9., 10.,  8.,  9., 10.,  8.,  9., 11.,
        18., 11., 11.,  1., 14., 12.,  8.,  7., 11.]])

2021-06-19:16:31:11,115 INFO     [divide_data.py:470] Raw class per worker is : array([[10., 11., 17.,  8.,  8., 11., 14.,  9., 15., 17., 13., 18., 11.,
         6.,  6., 15., 13.,  4., 11., 14.,  9., 10., 11., 13., 15.,  6.,
        17., 11.,  9.,  4., 11.,  9.,  9.,  7.,  7.],
       [14., 12., 19., 13., 15., 15., 14.,  6., 16., 15., 13., 12., 10.,
         4.,  9., 12.,  4.,  6., 18., 17., 14.,  7.,  5.,  7., 12.,  6.,
         9., 11., 12.,  4., 14., 12.,  9.,  6.,  7.],
       [ 3., 11., 13., 14.,  6., 16., 13., 11., 17., 12., 16.,  9.,  9.,
         7.,  9., 17.,  5.,  2., 11., 10.,  7., 11., 12.,  6., 21., 11.,
        18., 11., 16.,  5., 13., 14.,  6.,  8.,  9.],
       [12., 10., 11., 10., 14., 13., 15., 10., 12., 16., 10., 16., 10.,
        12.,  4., 10.,  4.,  8., 12.,  4., 12.,  6., 12., 11., 13., 17.,
        10., 15.,  7.,  7., 16., 11.,  5., 12., 12.],
       [17., 10., 10., 13., 10., 17., 18.,  5., 11., 14.,  5., 11.,  9.,
         6.,  6., 22.,  6.,  3., 17., 13., 13.,  5., 13.,  6., 13., 10.,
        20., 14., 10.,  6., 14., 10.,  8.,  8.,  6.],
       [ 8., 10., 13., 10.,  9., 12., 14.,  8., 18., 19.,  9., 15., 18.,
        13.,  8., 13.,  8.,  7., 14.,  7.,  8.,  6., 13.,  6., 17.,  8.,
         6., 17., 13., 10., 18.,  8.,  6.,  4.,  6.],
       [10.,  5., 10., 22.,  9., 14., 24., 12., 12., 12.,  7., 11., 19.,
         9.,  7., 13.,  7.,  9.,  9., 10.,  8.,  9., 10.,  8.,  9., 11.,
        18., 11., 11.,  1., 14., 12.,  8.,  7., 11.]])

2021-06-19:16:31:11,143 INFO     [divide_data.py:471] ========= End of Class/Worker =========

2021-06-19:16:31:11,143 INFO     [divide_data.py:471] ========= End of Class/Worker =========

2021-06-19:16:31:11,123 INFO     [divide_data.py:470] Raw class per worker is : array([[10., 11., 17.,  8.,  8., 11., 14.,  9., 15., 17., 13., 18., 11.,
         6.,  6., 15., 13.,  4., 11., 14.,  9., 10., 11., 13., 15.,  6.,
        17., 11.,  9.,  4., 11.,  9.,  9.,  7.,  7.],
       [14., 12., 19., 13., 15., 15., 14.,  6., 16., 15., 13., 12., 10.,
         4.,  9., 12.,  4.,  6., 18., 17., 14.,  7.,  5.,  7., 12.,  6.,
         9., 11., 12.,  4., 14., 12.,  9.,  6.,  7.],
       [ 3., 11., 13., 14.,  6., 16., 13., 11., 17., 12., 16.,  9.,  9.,
         7.,  9., 17.,  5.,  2., 11., 10.,  7., 11., 12.,  6., 21., 11.,
        18., 11., 16.,  5., 13., 14.,  6.,  8.,  9.],
       [12., 10., 11., 10., 14., 13., 15., 10., 12., 16., 10., 16., 10.,
        12.,  4., 10.,  4.,  8., 12.,  4., 12.,  6., 12., 11., 13., 17.,
        10., 15.,  7.,  7., 16., 11.,  5., 12., 12.],
       [17., 10., 10., 13., 10., 17., 18.,  5., 11., 14.,  5., 11.,  9.,
         6.,  6., 22.,  6.,  3., 17., 13., 13.,  5., 13.,  6., 13., 10.,
        20., 14., 10.,  6., 14., 10.,  8.,  8.,  6.],
       [ 8., 10., 13., 10.,  9., 12., 14.,  8., 18., 19.,  9., 15., 18.,
        13.,  8., 13.,  8.,  7., 14.,  7.,  8.,  6., 13.,  6., 17.,  8.,
         6., 17., 13., 10., 18.,  8.,  6.,  4.,  6.],
       [10.,  5., 10., 22.,  9., 14., 24., 12., 12., 12.,  7., 11., 19.,
         9.,  7., 13.,  7.,  9.,  9., 10.,  8.,  9., 10.,  8.,  9., 11.,
        18., 11., 11.,  1., 14., 12.,  8.,  7., 11.]])

2021-06-19:16:31:11,144 INFO     [divide_data.py:471] ========= End of Class/Worker =========

2021-06-19:16:31:11,147 INFO     [divide_data.py:471] ========= End of Class/Worker =========

2021-06-19:16:31:11,130 INFO     [divide_data.py:470] Raw class per worker is : array([[10., 11., 17.,  8.,  8., 11., 14.,  9., 15., 17., 13., 18., 11.,
         6.,  6., 15., 13.,  4., 11., 14.,  9., 10., 11., 13., 15.,  6.,
        17., 11.,  9.,  4., 11.,  9.,  9.,  7.,  7.],
       [14., 12., 19., 13., 15., 15., 14.,  6., 16., 15., 13., 12., 10.,
         4.,  9., 12.,  4.,  6., 18., 17., 14.,  7.,  5.,  7., 12.,  6.,
         9., 11., 12.,  4., 14., 12.,  9.,  6.,  7.],
       [ 3., 11., 13., 14.,  6., 16., 13., 11., 17., 12., 16.,  9.,  9.,
         7.,  9., 17.,  5.,  2., 11., 10.,  7., 11., 12.,  6., 21., 11.,
        18., 11., 16.,  5., 13., 14.,  6.,  8.,  9.],
       [12., 10., 11., 10., 14., 13., 15., 10., 12., 16., 10., 16., 10.,
        12.,  4., 10.,  4.,  8., 12.,  4., 12.,  6., 12., 11., 13., 17.,
        10., 15.,  7.,  7., 16., 11.,  5., 12., 12.],
       [17., 10., 10., 13., 10., 17., 18.,  5., 11., 14.,  5., 11.,  9.,
         6.,  6., 22.,  6.,  3., 17., 13., 13.,  5., 13.,  6., 13., 10.,
        20., 14., 10.,  6., 14., 10.,  8.,  8.,  6.],
       [ 8., 10., 13., 10.,  9., 12., 14.,  8., 18., 19.,  9., 15., 18.,
        13.,  8., 13.,  8.,  7., 14.,  7.,  8.,  6., 13.,  6., 17.,  8.,
         6., 17., 13., 10., 18.,  8.,  6.,  4.,  6.],
       [10.,  5., 10., 22.,  9., 14., 24., 12., 12., 12.,  7., 11., 19.,
         9.,  7., 13.,  7.,  9.,  9., 10.,  8.,  9., 10.,  8.,  9., 11.,
        18., 11., 11.,  1., 14., 12.,  8.,  7., 11.]])

2021-06-19:16:31:11,136 INFO     [divide_data.py:470] Raw class per worker is : array([[10., 11., 17.,  8.,  8., 11., 14.,  9., 15., 17., 13., 18., 11.,
         6.,  6., 15., 13.,  4., 11., 14.,  9., 10., 11., 13., 15.,  6.,
        17., 11.,  9.,  4., 11.,  9.,  9.,  7.,  7.],
       [14., 12., 19., 13., 15., 15., 14.,  6., 16., 15., 13., 12., 10.,
         4.,  9., 12.,  4.,  6., 18., 17., 14.,  7.,  5.,  7., 12.,  6.,
         9., 11., 12.,  4., 14., 12.,  9.,  6.,  7.],
       [ 3., 11., 13., 14.,  6., 16., 13., 11., 17., 12., 16.,  9.,  9.,
         7.,  9., 17.,  5.,  2., 11., 10.,  7., 11., 12.,  6., 21., 11.,
        18., 11., 16.,  5., 13., 14.,  6.,  8.,  9.],
       [12., 10., 11., 10., 14., 13., 15., 10., 12., 16., 10., 16., 10.,
        12.,  4., 10.,  4.,  8., 12.,  4., 12.,  6., 12., 11., 13., 17.,
        10., 15.,  7.,  7., 16., 11.,  5., 12., 12.],
       [17., 10., 10., 13., 10., 17., 18.,  5., 11., 14.,  5., 11.,  9.,
         6.,  6., 22.,  6.,  3., 17., 13., 13.,  5., 13.,  6., 13., 10.,
        20., 14., 10.,  6., 14., 10.,  8.,  8.,  6.],
       [ 8., 10., 13., 10.,  9., 12., 14.,  8., 18., 19.,  9., 15., 18.,
        13.,  8., 13.,  8.,  7., 14.,  7.,  8.,  6., 13.,  6., 17.,  8.,
         6., 17., 13., 10., 18.,  8.,  6.,  4.,  6.],
       [10.,  5., 10., 22.,  9., 14., 24., 12., 12., 12.,  7., 11., 19.,
         9.,  7., 13.,  7.,  9.,  9., 10.,  8.,  9., 10.,  8.,  9., 11.,
        18., 11., 11.,  1., 14., 12.,  8.,  7., 11.]])

2021-06-19:16:31:11,149 INFO     [divide_data.py:471] ========= End of Class/Worker =========

2021-06-19:16:31:11,154 INFO     [divide_data.py:471] ========= End of Class/Worker =========

2021-06-19:16:31:11,141 INFO     [divide_data.py:470] Raw class per worker is : array([[10., 11., 17.,  8.,  8., 11., 14.,  9., 15., 17., 13., 18., 11.,
         6.,  6., 15., 13.,  4., 11., 14.,  9., 10., 11., 13., 15.,  6.,
        17., 11.,  9.,  4., 11.,  9.,  9.,  7.,  7.],
       [14., 12., 19., 13., 15., 15., 14.,  6., 16., 15., 13., 12., 10.,
         4.,  9., 12.,  4.,  6., 18., 17., 14.,  7.,  5.,  7., 12.,  6.,
         9., 11., 12.,  4., 14., 12.,  9.,  6.,  7.],
       [ 3., 11., 13., 14.,  6., 16., 13., 11., 17., 12., 16.,  9.,  9.,
         7.,  9., 17.,  5.,  2., 11., 10.,  7., 11., 12.,  6., 21., 11.,
        18., 11., 16.,  5., 13., 14.,  6.,  8.,  9.],
       [12., 10., 11., 10., 14., 13., 15., 10., 12., 16., 10., 16., 10.,
        12.,  4., 10.,  4.,  8., 12.,  4., 12.,  6., 12., 11., 13., 17.,
        10., 15.,  7.,  7., 16., 11.,  5., 12., 12.],
       [17., 10., 10., 13., 10., 17., 18.,  5., 11., 14.,  5., 11.,  9.,
         6.,  6., 22.,  6.,  3., 17., 13., 13.,  5., 13.,  6., 13., 10.,
        20., 14., 10.,  6., 14., 10.,  8.,  8.,  6.],
       [ 8., 10., 13., 10.,  9., 12., 14.,  8., 18., 19.,  9., 15., 18.,
        13.,  8., 13.,  8.,  7., 14.,  7.,  8.,  6., 13.,  6., 17.,  8.,
         6., 17., 13., 10., 18.,  8.,  6.,  4.,  6.],
       [10.,  5., 10., 22.,  9., 14., 24., 12., 12., 12.,  7., 11., 19.,
         9.,  7., 13.,  7.,  9.,  9., 10.,  8.,  9., 10.,  8.,  9., 11.,
        18., 11., 11.,  1., 14., 12.,  8.,  7., 11.]])

2021-06-19:16:31:11,156 INFO     [divide_data.py:471] ========= End of Class/Worker =========

2021-06-19:16:31:11,177 INFO     [learner.py:393] ====Worker: Start running
2021-06-19:16:31:11,181 INFO     [learner.py:393] ====Worker: Start running
2021-06-19:16:31:11,180 INFO     [learner.py:393] ====Worker: Start running
2021-06-19:16:31:11,182 INFO     [learner.py:393] ====Worker: Start running
2021-06-19:16:31:11,183 INFO     [learner.py:393] ====Worker: Start running
2021-06-19:16:31:11,179 INFO     [learner.py:393] ====Worker: Start running
2021-06-19:16:31:11,176 INFO     [learner.py:393] ====Worker: Start running
2021-06-19:16:31:11,541 INFO     [learner.py:429] 
Namespace(adam_epsilon=1e-08, backend='nccl', batch_size=16, bidirectional=True, blacklist_max_len=0.3, blacklist_rounds=-1, block_size=64, cache_dir=None, capacity_bin=True, clf_block_size=100, client_path='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/data/device_info/client_profile.pkl', clip_bound=0.98, clock_factor=6.092057761732853, conf_path='~/dataset/', config_name=None, cut_off_util=0.4, data_dir='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/google_speech', data_mapfile='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/google_speech/clientDataMap', data_set='google_speech', decay_epoch=15.0, decay_factor=0.95, display_step=20, do_eval=False, do_train=False, dump_epoch=1000, duplicate_data=1, enforce_random=False, epochs=500, eval_all_checkpoints=False, eval_data_file='', eval_interval=20, eval_interval_prior=9999999, evaluate_during_training=False, exploration_alpha=0.3, exploration_decay=0.95, exploration_factor=0.9, exploration_min=0.2, filter_class=0, filter_less=16, filter_more=100000.0, finetune=False, fixed_clients=False, force_read=False, forward_pass=False, fp16=False, fp16_opt_level='O1', full_gradient_interval=20, gpu_device=0, gradient_accumulation_steps=1, gradient_policy='yogi', hetero_allocation='1.0-1.0-1.0-1.0-1.0-1.0', heterogeneity=1.0, hidden_layers=7, hidden_size=256, input_dim=0, is_even_avg=True, job_name='google_speech', labels_path='labels.json', learners='1-2-3-4-5-6-7', learning_rate=0.04, line_by_line=False, load_model=False, local_rank=-1, log_path='/mnt/home/lichenni/projects/Oort/training/evals', logging_steps=500, loss_decay=0.2, malicious_clients=0, manager_port=9702, max_grad_norm=1.0, max_iter_store=100, max_steps=-1, min_learning_rate=0.0001, mlm=True, mlm_probability=0.1, model='resnet34', model_avg=True, model_name_or_path=None, model_path=None, model_size=65536, model_type='', no_cuda=False, noise_dir=None, noise_factor=0, noise_max=0.5, noise_min=0.0, noise_prob=0.4, num_class=35, num_classes=35, num_loaders=2, num_train_epochs=1.0, output_dim=0, output_dir=None, overcommit=1.1, overwrite_cache=False, overwrite_output_dir=False, pacer_delta=30.0, pacer_step=20, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, proxy_avg=False, proxy_mu=0.1, ps_ip='lac-348', ps_port='4680', read_models_path=False, release_cache=False, resampling_interval=1, rnn_type='lstm', round_penalty=2.0, round_threshold=30.0, run_all=False, sample_mode='random', sample_rate=16000, sample_seed=233, sample_window=5.0, sampler_path=None, save_path='./', save_steps=500, save_total_limit=None, score_mode='loss', seed=42, sequential='0', server_ip='', server_port='', should_continue=False, single_sim=0, skip_partition=False, sleep_up=0, spec_augment=False, speed_volume_perturb=False, stale_threshold=0, task='speech', test_bsz=256, test_interval=20, test_manifest='data/test_manifest.csv', test_only=False, test_ratio=1.0, test_train_data=False, this_rank=3, threads=4, time_stamp='0619_162733', timeout=9999999, to_device='cuda', tokenizer_name=None, total_worker=28, train_data_file='', train_manifest='data/train_manifest.csv', upload_epoch=20, user_trace=None, validate_interval=999999, vocab_tag_size=500, vocab_token_size=10000, warmup_steps=0, weight_decay=0.0, window='hamming', window_size=0.02, window_stride=0.01, yogi_beta=0.999, yogi_beta2=-1, yogi_eta=0.005, yogi_tau=0.001, zipf_alpha='5')

2021-06-19:16:31:11,542 INFO     [learner.py:429] 
Namespace(adam_epsilon=1e-08, backend='nccl', batch_size=16, bidirectional=True, blacklist_max_len=0.3, blacklist_rounds=-1, block_size=64, cache_dir=None, capacity_bin=True, clf_block_size=100, client_path='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/data/device_info/client_profile.pkl', clip_bound=0.98, clock_factor=6.092057761732853, conf_path='~/dataset/', config_name=None, cut_off_util=0.4, data_dir='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/google_speech', data_mapfile='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/google_speech/clientDataMap', data_set='google_speech', decay_epoch=15.0, decay_factor=0.95, display_step=20, do_eval=False, do_train=False, dump_epoch=1000, duplicate_data=1, enforce_random=False, epochs=500, eval_all_checkpoints=False, eval_data_file='', eval_interval=20, eval_interval_prior=9999999, evaluate_during_training=False, exploration_alpha=0.3, exploration_decay=0.95, exploration_factor=0.9, exploration_min=0.2, filter_class=0, filter_less=16, filter_more=100000.0, finetune=False, fixed_clients=False, force_read=False, forward_pass=False, fp16=False, fp16_opt_level='O1', full_gradient_interval=20, gpu_device=0, gradient_accumulation_steps=1, gradient_policy='yogi', hetero_allocation='1.0-1.0-1.0-1.0-1.0-1.0', heterogeneity=1.0, hidden_layers=7, hidden_size=256, input_dim=0, is_even_avg=True, job_name='google_speech', labels_path='labels.json', learners='1-2-3-4-5-6-7', learning_rate=0.04, line_by_line=False, load_model=False, local_rank=-1, log_path='/mnt/home/lichenni/projects/Oort/training/evals', logging_steps=500, loss_decay=0.2, malicious_clients=0, manager_port=9702, max_grad_norm=1.0, max_iter_store=100, max_steps=-1, min_learning_rate=0.0001, mlm=True, mlm_probability=0.1, model='resnet34', model_avg=True, model_name_or_path=None, model_path=None, model_size=65536, model_type='', no_cuda=False, noise_dir=None, noise_factor=0, noise_max=0.5, noise_min=0.0, noise_prob=0.4, num_class=35, num_classes=35, num_loaders=2, num_train_epochs=1.0, output_dim=0, output_dir=None, overcommit=1.1, overwrite_cache=False, overwrite_output_dir=False, pacer_delta=30.0, pacer_step=20, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, proxy_avg=False, proxy_mu=0.1, ps_ip='lac-348', ps_port='4680', read_models_path=False, release_cache=False, resampling_interval=1, rnn_type='lstm', round_penalty=2.0, round_threshold=30.0, run_all=False, sample_mode='random', sample_rate=16000, sample_seed=233, sample_window=5.0, sampler_path=None, save_path='./', save_steps=500, save_total_limit=None, score_mode='loss', seed=42, sequential='0', server_ip='', server_port='', should_continue=False, single_sim=0, skip_partition=False, sleep_up=0, spec_augment=False, speed_volume_perturb=False, stale_threshold=0, task='speech', test_bsz=256, test_interval=20, test_manifest='data/test_manifest.csv', test_only=False, test_ratio=1.0, test_train_data=False, this_rank=2, threads=4, time_stamp='0619_162733', timeout=9999999, to_device='cuda', tokenizer_name=None, total_worker=28, train_data_file='', train_manifest='data/train_manifest.csv', upload_epoch=20, user_trace=None, validate_interval=999999, vocab_tag_size=500, vocab_token_size=10000, warmup_steps=0, weight_decay=0.0, window='hamming', window_size=0.02, window_stride=0.01, yogi_beta=0.999, yogi_beta2=-1, yogi_eta=0.005, yogi_tau=0.001, zipf_alpha='5')

2021-06-19:16:31:11,543 INFO     [learner.py:429] 
Namespace(adam_epsilon=1e-08, backend='nccl', batch_size=16, bidirectional=True, blacklist_max_len=0.3, blacklist_rounds=-1, block_size=64, cache_dir=None, capacity_bin=True, clf_block_size=100, client_path='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/data/device_info/client_profile.pkl', clip_bound=0.98, clock_factor=6.092057761732853, conf_path='~/dataset/', config_name=None, cut_off_util=0.4, data_dir='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/google_speech', data_mapfile='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/google_speech/clientDataMap', data_set='google_speech', decay_epoch=15.0, decay_factor=0.95, display_step=20, do_eval=False, do_train=False, dump_epoch=1000, duplicate_data=1, enforce_random=False, epochs=500, eval_all_checkpoints=False, eval_data_file='', eval_interval=20, eval_interval_prior=9999999, evaluate_during_training=False, exploration_alpha=0.3, exploration_decay=0.95, exploration_factor=0.9, exploration_min=0.2, filter_class=0, filter_less=16, filter_more=100000.0, finetune=False, fixed_clients=False, force_read=False, forward_pass=False, fp16=False, fp16_opt_level='O1', full_gradient_interval=20, gpu_device=0, gradient_accumulation_steps=1, gradient_policy='yogi', hetero_allocation='1.0-1.0-1.0-1.0-1.0-1.0', heterogeneity=1.0, hidden_layers=7, hidden_size=256, input_dim=0, is_even_avg=True, job_name='google_speech', labels_path='labels.json', learners='1-2-3-4-5-6-7', learning_rate=0.04, line_by_line=False, load_model=False, local_rank=-1, log_path='/mnt/home/lichenni/projects/Oort/training/evals', logging_steps=500, loss_decay=0.2, malicious_clients=0, manager_port=9702, max_grad_norm=1.0, max_iter_store=100, max_steps=-1, min_learning_rate=0.0001, mlm=True, mlm_probability=0.1, model='resnet34', model_avg=True, model_name_or_path=None, model_path=None, model_size=65536, model_type='', no_cuda=False, noise_dir=None, noise_factor=0, noise_max=0.5, noise_min=0.0, noise_prob=0.4, num_class=35, num_classes=35, num_loaders=2, num_train_epochs=1.0, output_dim=0, output_dir=None, overcommit=1.1, overwrite_cache=False, overwrite_output_dir=False, pacer_delta=30.0, pacer_step=20, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, proxy_avg=False, proxy_mu=0.1, ps_ip='lac-348', ps_port='4680', read_models_path=False, release_cache=False, resampling_interval=1, rnn_type='lstm', round_penalty=2.0, round_threshold=30.0, run_all=False, sample_mode='random', sample_rate=16000, sample_seed=233, sample_window=5.0, sampler_path=None, save_path='./', save_steps=500, save_total_limit=None, score_mode='loss', seed=42, sequential='0', server_ip='', server_port='', should_continue=False, single_sim=0, skip_partition=False, sleep_up=0, spec_augment=False, speed_volume_perturb=False, stale_threshold=0, task='speech', test_bsz=256, test_interval=20, test_manifest='data/test_manifest.csv', test_only=False, test_ratio=1.0, test_train_data=False, this_rank=4, threads=4, time_stamp='0619_162733', timeout=9999999, to_device='cuda', tokenizer_name=None, total_worker=28, train_data_file='', train_manifest='data/train_manifest.csv', upload_epoch=20, user_trace=None, validate_interval=999999, vocab_tag_size=500, vocab_token_size=10000, warmup_steps=0, weight_decay=0.0, window='hamming', window_size=0.02, window_stride=0.01, yogi_beta=0.999, yogi_beta2=-1, yogi_eta=0.005, yogi_tau=0.001, zipf_alpha='5')

2021-06-19:16:31:11,545 INFO     [learner.py:429] 
Namespace(adam_epsilon=1e-08, backend='nccl', batch_size=16, bidirectional=True, blacklist_max_len=0.3, blacklist_rounds=-1, block_size=64, cache_dir=None, capacity_bin=True, clf_block_size=100, client_path='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/data/device_info/client_profile.pkl', clip_bound=0.98, clock_factor=6.092057761732853, conf_path='~/dataset/', config_name=None, cut_off_util=0.4, data_dir='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/google_speech', data_mapfile='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/google_speech/clientDataMap', data_set='google_speech', decay_epoch=15.0, decay_factor=0.95, display_step=20, do_eval=False, do_train=False, dump_epoch=1000, duplicate_data=1, enforce_random=False, epochs=500, eval_all_checkpoints=False, eval_data_file='', eval_interval=20, eval_interval_prior=9999999, evaluate_during_training=False, exploration_alpha=0.3, exploration_decay=0.95, exploration_factor=0.9, exploration_min=0.2, filter_class=0, filter_less=16, filter_more=100000.0, finetune=False, fixed_clients=False, force_read=False, forward_pass=False, fp16=False, fp16_opt_level='O1', full_gradient_interval=20, gpu_device=0, gradient_accumulation_steps=1, gradient_policy='yogi', hetero_allocation='1.0-1.0-1.0-1.0-1.0-1.0', heterogeneity=1.0, hidden_layers=7, hidden_size=256, input_dim=0, is_even_avg=True, job_name='google_speech', labels_path='labels.json', learners='1-2-3-4-5-6-7', learning_rate=0.04, line_by_line=False, load_model=False, local_rank=-1, log_path='/mnt/home/lichenni/projects/Oort/training/evals', logging_steps=500, loss_decay=0.2, malicious_clients=0, manager_port=9702, max_grad_norm=1.0, max_iter_store=100, max_steps=-1, min_learning_rate=0.0001, mlm=True, mlm_probability=0.1, model='resnet34', model_avg=True, model_name_or_path=None, model_path=None, model_size=65536, model_type='', no_cuda=False, noise_dir=None, noise_factor=0, noise_max=0.5, noise_min=0.0, noise_prob=0.4, num_class=35, num_classes=35, num_loaders=2, num_train_epochs=1.0, output_dim=0, output_dir=None, overcommit=1.1, overwrite_cache=False, overwrite_output_dir=False, pacer_delta=30.0, pacer_step=20, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, proxy_avg=False, proxy_mu=0.1, ps_ip='lac-348', ps_port='4680', read_models_path=False, release_cache=False, resampling_interval=1, rnn_type='lstm', round_penalty=2.0, round_threshold=30.0, run_all=False, sample_mode='random', sample_rate=16000, sample_seed=233, sample_window=5.0, sampler_path=None, save_path='./', save_steps=500, save_total_limit=None, score_mode='loss', seed=42, sequential='0', server_ip='', server_port='', should_continue=False, single_sim=0, skip_partition=False, sleep_up=0, spec_augment=False, speed_volume_perturb=False, stale_threshold=0, task='speech', test_bsz=256, test_interval=20, test_manifest='data/test_manifest.csv', test_only=False, test_ratio=1.0, test_train_data=False, this_rank=1, threads=4, time_stamp='0619_162733', timeout=9999999, to_device='cuda', tokenizer_name=None, total_worker=28, train_data_file='', train_manifest='data/train_manifest.csv', upload_epoch=20, user_trace=None, validate_interval=999999, vocab_tag_size=500, vocab_token_size=10000, warmup_steps=0, weight_decay=0.0, window='hamming', window_size=0.02, window_stride=0.01, yogi_beta=0.999, yogi_beta2=-1, yogi_eta=0.005, yogi_tau=0.001, zipf_alpha='5')

2021-06-19:16:31:11,546 INFO     [learner.py:429] 
Namespace(adam_epsilon=1e-08, backend='nccl', batch_size=16, bidirectional=True, blacklist_max_len=0.3, blacklist_rounds=-1, block_size=64, cache_dir=None, capacity_bin=True, clf_block_size=100, client_path='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/data/device_info/client_profile.pkl', clip_bound=0.98, clock_factor=6.092057761732853, conf_path='~/dataset/', config_name=None, cut_off_util=0.4, data_dir='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/google_speech', data_mapfile='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/google_speech/clientDataMap', data_set='google_speech', decay_epoch=15.0, decay_factor=0.95, display_step=20, do_eval=False, do_train=False, dump_epoch=1000, duplicate_data=1, enforce_random=False, epochs=500, eval_all_checkpoints=False, eval_data_file='', eval_interval=20, eval_interval_prior=9999999, evaluate_during_training=False, exploration_alpha=0.3, exploration_decay=0.95, exploration_factor=0.9, exploration_min=0.2, filter_class=0, filter_less=16, filter_more=100000.0, finetune=False, fixed_clients=False, force_read=False, forward_pass=False, fp16=False, fp16_opt_level='O1', full_gradient_interval=20, gpu_device=0, gradient_accumulation_steps=1, gradient_policy='yogi', hetero_allocation='1.0-1.0-1.0-1.0-1.0-1.0', heterogeneity=1.0, hidden_layers=7, hidden_size=256, input_dim=0, is_even_avg=True, job_name='google_speech', labels_path='labels.json', learners='1-2-3-4-5-6-7', learning_rate=0.04, line_by_line=False, load_model=False, local_rank=-1, log_path='/mnt/home/lichenni/projects/Oort/training/evals', logging_steps=500, loss_decay=0.2, malicious_clients=0, manager_port=9702, max_grad_norm=1.0, max_iter_store=100, max_steps=-1, min_learning_rate=0.0001, mlm=True, mlm_probability=0.1, model='resnet34', model_avg=True, model_name_or_path=None, model_path=None, model_size=65536, model_type='', no_cuda=False, noise_dir=None, noise_factor=0, noise_max=0.5, noise_min=0.0, noise_prob=0.4, num_class=35, num_classes=35, num_loaders=2, num_train_epochs=1.0, output_dim=0, output_dir=None, overcommit=1.1, overwrite_cache=False, overwrite_output_dir=False, pacer_delta=30.0, pacer_step=20, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, proxy_avg=False, proxy_mu=0.1, ps_ip='lac-348', ps_port='4680', read_models_path=False, release_cache=False, resampling_interval=1, rnn_type='lstm', round_penalty=2.0, round_threshold=30.0, run_all=False, sample_mode='random', sample_rate=16000, sample_seed=233, sample_window=5.0, sampler_path=None, save_path='./', save_steps=500, save_total_limit=None, score_mode='loss', seed=42, sequential='0', server_ip='', server_port='', should_continue=False, single_sim=0, skip_partition=False, sleep_up=0, spec_augment=False, speed_volume_perturb=False, stale_threshold=0, task='speech', test_bsz=256, test_interval=20, test_manifest='data/test_manifest.csv', test_only=False, test_ratio=1.0, test_train_data=False, this_rank=7, threads=4, time_stamp='0619_162733', timeout=9999999, to_device='cuda', tokenizer_name=None, total_worker=28, train_data_file='', train_manifest='data/train_manifest.csv', upload_epoch=20, user_trace=None, validate_interval=999999, vocab_tag_size=500, vocab_token_size=10000, warmup_steps=0, weight_decay=0.0, window='hamming', window_size=0.02, window_stride=0.01, yogi_beta=0.999, yogi_beta2=-1, yogi_eta=0.005, yogi_tau=0.001, zipf_alpha='5')

2021-06-19:16:31:11,548 INFO     [learner.py:429] 
Namespace(adam_epsilon=1e-08, backend='nccl', batch_size=16, bidirectional=True, blacklist_max_len=0.3, blacklist_rounds=-1, block_size=64, cache_dir=None, capacity_bin=True, clf_block_size=100, client_path='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/data/device_info/client_profile.pkl', clip_bound=0.98, clock_factor=6.092057761732853, conf_path='~/dataset/', config_name=None, cut_off_util=0.4, data_dir='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/google_speech', data_mapfile='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/google_speech/clientDataMap', data_set='google_speech', decay_epoch=15.0, decay_factor=0.95, display_step=20, do_eval=False, do_train=False, dump_epoch=1000, duplicate_data=1, enforce_random=False, epochs=500, eval_all_checkpoints=False, eval_data_file='', eval_interval=20, eval_interval_prior=9999999, evaluate_during_training=False, exploration_alpha=0.3, exploration_decay=0.95, exploration_factor=0.9, exploration_min=0.2, filter_class=0, filter_less=16, filter_more=100000.0, finetune=False, fixed_clients=False, force_read=False, forward_pass=False, fp16=False, fp16_opt_level='O1', full_gradient_interval=20, gpu_device=0, gradient_accumulation_steps=1, gradient_policy='yogi', hetero_allocation='1.0-1.0-1.0-1.0-1.0-1.0', heterogeneity=1.0, hidden_layers=7, hidden_size=256, input_dim=0, is_even_avg=True, job_name='google_speech', labels_path='labels.json', learners='1-2-3-4-5-6-7', learning_rate=0.04, line_by_line=False, load_model=False, local_rank=-1, log_path='/mnt/home/lichenni/projects/Oort/training/evals', logging_steps=500, loss_decay=0.2, malicious_clients=0, manager_port=9702, max_grad_norm=1.0, max_iter_store=100, max_steps=-1, min_learning_rate=0.0001, mlm=True, mlm_probability=0.1, model='resnet34', model_avg=True, model_name_or_path=None, model_path=None, model_size=65536, model_type='', no_cuda=False, noise_dir=None, noise_factor=0, noise_max=0.5, noise_min=0.0, noise_prob=0.4, num_class=35, num_classes=35, num_loaders=2, num_train_epochs=1.0, output_dim=0, output_dir=None, overcommit=1.1, overwrite_cache=False, overwrite_output_dir=False, pacer_delta=30.0, pacer_step=20, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, proxy_avg=False, proxy_mu=0.1, ps_ip='lac-348', ps_port='4680', read_models_path=False, release_cache=False, resampling_interval=1, rnn_type='lstm', round_penalty=2.0, round_threshold=30.0, run_all=False, sample_mode='random', sample_rate=16000, sample_seed=233, sample_window=5.0, sampler_path=None, save_path='./', save_steps=500, save_total_limit=None, score_mode='loss', seed=42, sequential='0', server_ip='', server_port='', should_continue=False, single_sim=0, skip_partition=False, sleep_up=0, spec_augment=False, speed_volume_perturb=False, stale_threshold=0, task='speech', test_bsz=256, test_interval=20, test_manifest='data/test_manifest.csv', test_only=False, test_ratio=1.0, test_train_data=False, this_rank=6, threads=4, time_stamp='0619_162733', timeout=9999999, to_device='cuda', tokenizer_name=None, total_worker=28, train_data_file='', train_manifest='data/train_manifest.csv', upload_epoch=20, user_trace=None, validate_interval=999999, vocab_tag_size=500, vocab_token_size=10000, warmup_steps=0, weight_decay=0.0, window='hamming', window_size=0.02, window_stride=0.01, yogi_beta=0.999, yogi_beta2=-1, yogi_eta=0.005, yogi_tau=0.001, zipf_alpha='5')

2021-06-19:16:31:11,549 INFO     [learner.py:429] 
Namespace(adam_epsilon=1e-08, backend='nccl', batch_size=16, bidirectional=True, blacklist_max_len=0.3, blacklist_rounds=-1, block_size=64, cache_dir=None, capacity_bin=True, clf_block_size=100, client_path='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/data/device_info/client_profile.pkl', clip_bound=0.98, clock_factor=6.092057761732853, conf_path='~/dataset/', config_name=None, cut_off_util=0.4, data_dir='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/google_speech', data_mapfile='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/google_speech/clientDataMap', data_set='google_speech', decay_epoch=15.0, decay_factor=0.95, display_step=20, do_eval=False, do_train=False, dump_epoch=1000, duplicate_data=1, enforce_random=False, epochs=500, eval_all_checkpoints=False, eval_data_file='', eval_interval=20, eval_interval_prior=9999999, evaluate_during_training=False, exploration_alpha=0.3, exploration_decay=0.95, exploration_factor=0.9, exploration_min=0.2, filter_class=0, filter_less=16, filter_more=100000.0, finetune=False, fixed_clients=False, force_read=False, forward_pass=False, fp16=False, fp16_opt_level='O1', full_gradient_interval=20, gpu_device=0, gradient_accumulation_steps=1, gradient_policy='yogi', hetero_allocation='1.0-1.0-1.0-1.0-1.0-1.0', heterogeneity=1.0, hidden_layers=7, hidden_size=256, input_dim=0, is_even_avg=True, job_name='google_speech', labels_path='labels.json', learners='1-2-3-4-5-6-7', learning_rate=0.04, line_by_line=False, load_model=False, local_rank=-1, log_path='/mnt/home/lichenni/projects/Oort/training/evals', logging_steps=500, loss_decay=0.2, malicious_clients=0, manager_port=9702, max_grad_norm=1.0, max_iter_store=100, max_steps=-1, min_learning_rate=0.0001, mlm=True, mlm_probability=0.1, model='resnet34', model_avg=True, model_name_or_path=None, model_path=None, model_size=65536, model_type='', no_cuda=False, noise_dir=None, noise_factor=0, noise_max=0.5, noise_min=0.0, noise_prob=0.4, num_class=35, num_classes=35, num_loaders=2, num_train_epochs=1.0, output_dim=0, output_dir=None, overcommit=1.1, overwrite_cache=False, overwrite_output_dir=False, pacer_delta=30.0, pacer_step=20, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, proxy_avg=False, proxy_mu=0.1, ps_ip='lac-348', ps_port='4680', read_models_path=False, release_cache=False, resampling_interval=1, rnn_type='lstm', round_penalty=2.0, round_threshold=30.0, run_all=False, sample_mode='random', sample_rate=16000, sample_seed=233, sample_window=5.0, sampler_path=None, save_path='./', save_steps=500, save_total_limit=None, score_mode='loss', seed=42, sequential='0', server_ip='', server_port='', should_continue=False, single_sim=0, skip_partition=False, sleep_up=0, spec_augment=False, speed_volume_perturb=False, stale_threshold=0, task='speech', test_bsz=256, test_interval=20, test_manifest='data/test_manifest.csv', test_only=False, test_ratio=1.0, test_train_data=False, this_rank=5, threads=4, time_stamp='0619_162733', timeout=9999999, to_device='cuda', tokenizer_name=None, total_worker=28, train_data_file='', train_manifest='data/train_manifest.csv', upload_epoch=20, user_trace=None, validate_interval=999999, vocab_tag_size=500, vocab_token_size=10000, warmup_steps=0, weight_decay=0.0, window='hamming', window_size=0.02, window_stride=0.01, yogi_beta=0.999, yogi_beta2=-1, yogi_eta=0.005, yogi_tau=0.001, zipf_alpha='5')

2021-06-19:16:31:13,438 INFO     [learner.py:151] Start to run client 1 ...
2021-06-19:16:31:13,478 INFO     [learner.py:151] Start to run client 4 ...
====Worker: init_myprocesses
Begin!
====Worker: init_myprocesses
Begin!
2021-06-19:16:31:13,531 INFO     [learner.py:151] Start to run client 5 ...
2021-06-19:16:31:13,528 INFO     [learner.py:151] Start to run client 6 ...
====Worker: init_myprocesses
Begin!
2021-06-19:16:31:13,562 INFO     [learner.py:151] Start to run client 2 ...
====Worker: init_myprocesses
Begin!
2021-06-19:16:31:13,565 INFO     [learner.py:151] Start to run client 7 ...
2021-06-19:16:31:13,552 INFO     [learner.py:151] Start to run client 3 ...
====Worker: init_myprocesses
Begin!
====Worker: init_myprocesses
Begin!
====Worker: init_myprocesses
Begin!
2021-06-19:16:31:38,247 INFO     [learner.py:387] Completed to run client 6
2021-06-19:16:31:39,379 INFO     [learner.py:387] Completed to run client 2
2021-06-19:16:31:39,719 INFO     [learner.py:387] Completed to run client 7
2021-06-19:16:31:40,467 INFO     [learner.py:550] ====Pushing takes 2.1440482139587402 s
2021-06-19:16:31:41,781 INFO     [learner.py:550] ====Pushing takes 2.3847992420196533 s
2021-06-19:16:31:42,131 INFO     [param_server.py:220] ====Start to merge models
2021-06-19:16:31:42,256 INFO     [learner.py:550] ====Pushing takes 2.4316158294677734 s
2021-06-19:16:31:42,336 INFO     [param_server.py:278] ====Done handling rank 6, with ratio 0.14285714285714285, now collected 1 clients
2021-06-19:16:31:42,378 INFO     [param_server.py:328] Lock worker 6 with localStep 1 , while globalStep is 0

2021-06-19:16:31:42,630 INFO     [learner.py:387] Completed to run client 1
2021-06-19:16:31:44,353 INFO     [learner.py:550] ====Pushing takes 1.6832106113433838 s
2021-06-19:16:31:44,473 INFO     [param_server.py:220] ====Start to merge models
2021-06-19:16:31:44,881 INFO     [param_server.py:278] ====Done handling rank 2, with ratio 0.14285714285714285, now collected 2 clients
2021-06-19:16:31:44,898 INFO     [param_server.py:328] Lock worker 2 with localStep 1 , while globalStep is 0

2021-06-19:16:31:47,401 INFO     [param_server.py:220] ====Start to merge models
2021-06-19:16:31:47,765 INFO     [param_server.py:278] ====Done handling rank 7, with ratio 0.14285714285714285, now collected 3 clients
2021-06-19:16:31:47,785 INFO     [param_server.py:328] Lock worker 7 with localStep 1 , while globalStep is 0

2021-06-19:16:31:49,636 INFO     [param_server.py:220] ====Start to merge models
2021-06-19:16:31:50,9 INFO     [param_server.py:278] ====Done handling rank 1, with ratio 0.14285714285714285, now collected 4 clients
2021-06-19:16:31:50,15 INFO     [param_server.py:328] Lock worker 1 with localStep 1 , while globalStep is 0

2021-06-19:16:32:06,921 INFO     [learner.py:387] Completed to run client 4
2021-06-19:16:32:08,1 INFO     [learner.py:387] Completed to run client 5
2021-06-19:16:32:08,158 INFO     [learner.py:387] Completed to run client 3
2021-06-19:16:32:08,757 INFO     [learner.py:550] ====Pushing takes 1.7939293384552002 s
2021-06-19:16:32:11,110 INFO     [learner.py:550] ====Pushing takes 2.9253487586975098 s
2021-06-19:16:32:11,736 INFO     [param_server.py:220] ====Start to merge models
2021-06-19:16:32:11,792 INFO     [learner.py:550] ====Pushing takes 3.761133909225464 s
2021-06-19:16:32:12,56 INFO     [param_server.py:278] ====Done handling rank 4, with ratio 0.14285714285714285, now collected 5 clients
2021-06-19:16:32:12,90 INFO     [param_server.py:328] Lock worker 4 with localStep 1 , while globalStep is 0

2021-06-19:16:32:14,725 INFO     [param_server.py:220] ====Start to merge models
2021-06-19:16:32:15,51 INFO     [param_server.py:278] ====Done handling rank 3, with ratio 0.14285714285714285, now collected 6 clients
2021-06-19:16:32:15,70 INFO     [param_server.py:328] Lock worker 3 with localStep 1 , while globalStep is 0

2021-06-19:16:32:17,124 INFO     [param_server.py:220] ====Start to merge models
2021-06-19:16:32:17,431 INFO     [param_server.py:278] ====Done handling rank 5, with ratio 0.14285714285714285, now collected 7 clients
2021-06-19:16:32:17,440 INFO     [param_server.py:300] ====After aggregation in epoch: 0, virtual_clock: 0.0, top_1: : 0.0 % (0.0), top_5: : 0.0 % (0.0), test loss: 0.0, test len: 7.0
2021-06-19:16:32:17,467 INFO     [param_server.py:328] Lock worker 5 with localStep 1 , while globalStep is 1

2021-06-19:16:32:17,468 INFO     [param_server.py:360] ====Epoch 2 completes 7 clients with loss 43.86381212535076, sampled rewards are: 
 {1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0} 
==========
2021-06-19:16:32:17,469 INFO     [param_server.py:369] ====Start to sample for epoch 2, global virtualClock: 0.0, round_duration: 0.0
2021-06-19:16:32:17,474 INFO     [param_server.py:389] ====Try to resample clients, final takes: 
 [29, 72, 202, 317, 340, 378, 448, 457, 498, 509, 686, 876, 890, 967, 1032, 1077, 1174, 1341, 1364, 1375, 1522, 1710, 1731, 1732, 1782, 1822, 1912, 2158]
2021-06-19:16:32:19,453 INFO     [learner.py:151] Start to run client 340 ...
2021-06-19:16:32:19,513 INFO     [learner.py:151] Start to run client 448 ...
2021-06-19:16:32:19,660 INFO     [learner.py:151] Start to run client 72 ...
2021-06-19:16:32:19,723 INFO     [learner.py:151] Start to run client 202 ...
2021-06-19:16:32:19,876 INFO     [learner.py:151] Start to run client 378 ...
2021-06-19:16:32:19,887 INFO     [learner.py:151] Start to run client 29 ...
2021-06-19:16:32:19,970 INFO     [learner.py:151] Start to run client 317 ...
2021-06-19:16:32:41,287 INFO     [learner.py:387] Completed to run client 72
2021-06-19:16:32:42,889 INFO     [learner.py:151] Start to run client 498 ...
2021-06-19:16:32:44,687 INFO     [learner.py:387] Completed to run client 29
2021-06-19:16:32:45,212 INFO     [learner.py:387] Completed to run client 317
2021-06-19:16:32:45,829 INFO     [learner.py:151] Start to run client 457 ...
2021-06-19:16:32:46,291 INFO     [learner.py:151] Start to run client 686 ...
2021-06-19:16:32:46,322 INFO     [learner.py:387] Completed to run client 378
2021-06-19:16:32:47,334 INFO     [learner.py:151] Start to run client 890 ...
2021-06-19:16:33:06,239 INFO     [learner.py:387] Completed to run client 457
2021-06-19:16:33:07,234 INFO     [learner.py:151] Start to run client 1032 ...
2021-06-19:16:33:15,105 INFO     [learner.py:387] Completed to run client 340
2021-06-19:16:33:15,923 INFO     [learner.py:151] Start to run client 876 ...
2021-06-19:16:33:16,393 INFO     [learner.py:387] Completed to run client 202
2021-06-19:16:33:17,667 INFO     [learner.py:151] Start to run client 509 ...
2021-06-19:16:33:34,342 INFO     [learner.py:387] Completed to run client 498
2021-06-19:16:33:34,847 INFO     [learner.py:387] Completed to run client 876
2021-06-19:16:33:35,481 INFO     [learner.py:151] Start to run client 1077 ...
2021-06-19:16:33:35,898 INFO     [learner.py:151] Start to run client 1364 ...
2021-06-19:16:33:38,685 INFO     [learner.py:387] Completed to run client 686
2021-06-19:16:33:39,580 INFO     [learner.py:387] Completed to run client 890
2021-06-19:16:33:39,763 INFO     [learner.py:151] Start to run client 1341 ...
2021-06-19:16:33:40,660 INFO     [learner.py:151] Start to run client 1375 ...
2021-06-19:16:33:57,415 INFO     [learner.py:387] Completed to run client 1032
2021-06-19:16:33:58,630 INFO     [learner.py:151] Start to run client 1710 ...
2021-06-19:16:34:08,549 INFO     [learner.py:387] Completed to run client 509
2021-06-19:16:34:09,664 INFO     [learner.py:151] Start to run client 1174 ...
2021-06-19:16:34:24,134 INFO     [learner.py:387] Completed to run client 1077
2021-06-19:16:34:24,974 INFO     [learner.py:387] Completed to run client 1364
2021-06-19:16:34:25,199 INFO     [learner.py:151] Start to run client 1731 ...
2021-06-19:16:34:26,176 INFO     [learner.py:151] Start to run client 1822 ...
2021-06-19:16:34:27,676 INFO     [learner.py:387] Completed to run client 1341
2021-06-19:16:34:28,875 INFO     [learner.py:151] Start to run client 1782 ...
2021-06-19:16:34:29,955 INFO     [learner.py:387] Completed to run client 1375
2021-06-19:16:34:31,180 INFO     [learner.py:151] Start to run client 1912 ...
2021-06-19:16:34:48,995 INFO     [learner.py:387] Completed to run client 1710
2021-06-19:16:34:55,773 INFO     [learner.py:550] ====Pushing takes 6.751491546630859 s
2021-06-19:16:35:01,974 INFO     [learner.py:387] Completed to run client 1174
2021-06-19:16:35:02,141 INFO     [param_server.py:220] ====Start to merge models
2021-06-19:16:35:03,350 INFO     [learner.py:151] Start to run client 1732 ...
2021-06-19:16:35:03,866 INFO     [param_server.py:278] ====Done handling rank 1, with ratio 0.03571428571428571, now collected 4 clients
2021-06-19:16:35:03,877 INFO     [param_server.py:328] Lock worker 1 with localStep 2 , while globalStep is 1

2021-06-19:16:35:16,487 INFO     [learner.py:387] Completed to run client 1731
2021-06-19:16:35:17,625 INFO     [learner.py:387] Completed to run client 1822
2021-06-19:16:35:20,776 INFO     [learner.py:387] Completed to run client 1782
2021-06-19:16:35:22,448 INFO     [learner.py:387] Completed to run client 1912
2021-06-19:16:35:24,298 INFO     [learner.py:550] ====Pushing takes 7.763242483139038 s
2021-06-19:16:35:27,601 INFO     [learner.py:550] ====Pushing takes 9.9618399143219 s
2021-06-19:16:35:33,769 INFO     [param_server.py:220] ====Start to merge models
2021-06-19:16:35:34,481 INFO     [learner.py:550] ====Pushing takes 13.675342321395874 s
2021-06-19:16:35:34,556 INFO     [learner.py:550] ====Pushing takes 12.06957721710205 s
2021-06-19:16:35:34,625 INFO     [param_server.py:278] ====Done handling rank 2, with ratio 0.03571428571428571, now collected 8 clients
2021-06-19:16:35:34,649 INFO     [param_server.py:328] Lock worker 2 with localStep 2 , while globalStep is 1

2021-06-19:16:35:44,528 INFO     [param_server.py:220] ====Start to merge models
2021-06-19:16:35:45,924 INFO     [param_server.py:278] ====Done handling rank 5, with ratio 0.03571428571428571, now collected 12 clients
2021-06-19:16:35:45,935 INFO     [param_server.py:328] Lock worker 5 with localStep 2 , while globalStep is 1

2021-06-19:16:35:55,948 INFO     [param_server.py:220] ====Start to merge models
2021-06-19:16:35:57,282 INFO     [param_server.py:278] ====Done handling rank 4, with ratio 0.03571428571428571, now collected 16 clients
2021-06-19:16:35:57,302 INFO     [param_server.py:328] Lock worker 4 with localStep 2 , while globalStep is 1

2021-06-19:16:36:04,772 INFO     [param_server.py:220] ====Start to merge models
2021-06-19:16:36:06,172 INFO     [param_server.py:278] ====Done handling rank 6, with ratio 0.03571428571428571, now collected 20 clients
2021-06-19:16:36:06,191 INFO     [param_server.py:328] Lock worker 6 with localStep 2 , while globalStep is 1

2021-06-19:16:36:08,517 INFO     [learner.py:387] Completed to run client 1732
2021-06-19:16:36:16,302 INFO     [learner.py:550] ====Pushing takes 7.746397256851196 s
2021-06-19:16:36:27,536 INFO     [param_server.py:220] ====Start to merge models
2021-06-19:16:36:28,872 INFO     [param_server.py:278] ====Done handling rank 3, with ratio 0.03571428571428571, now collected 24 clients
2021-06-19:16:36:28,887 INFO     [param_server.py:328] Lock worker 3 with localStep 2 , while globalStep is 1

