/mnt/home/lichenni/anaconda3/envs/oort/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.
Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.
  from numba.decorators import jit as optional_jit
2021-07-04:10:42:47,208 INFO     [param_server.py:12] End up with cuda device tensor([0.1113], device='cuda:0')
2021-07-04:10:42:47,665 INFO     [param_server.py:532] ====Start to initialize dataset
2021-07-04:10:42:47,666 INFO     [flLibs.py:59] ====Initialize the model
/mnt/home/lichenni/anaconda3/envs/oort/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.
Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.
  from numba.decorators import jit as optional_jit
2021-07-04:10:42:57,288 INFO     [learner.py:14] End up with cuda device tensor([0.2271], device='cuda:0')
2021-07-04:10:42:57,291 INFO     [learner.py:40] ===== Experiment start on : dev-amd20-v100=====
2021-07-04:10:42:57,709 INFO     [learner.py:707] ====Start to initialize dataset
2021-07-04:10:42:57,711 INFO     [flLibs.py:59] ====Initialize the model
2021-07-04:10:42:58,454 INFO     [learner.py:730] ==== Starting training data partitioner =====
2021-07-04:10:42:58,480 INFO     [divide_data.py:95] ====Initiating DataPartitioner takes 0.0206143856048584 s

2021-07-04:10:42:58,481 INFO     [learner.py:733] ==== Finished training data partitioner =====
2021-07-04:10:42:58,734 INFO     [learner.py:87] ====Save obs_client====
2021-07-04:10:42:58,825 INFO     [param_server.py:78] ====Info of all feasible clients {'total_feasible_clients': 2167, 'total_length': 102851}
2021-07-04:10:42:59,48 INFO     [param_server.py:139] ====PS: get in run()
2021-07-04:10:42:59,50 INFO     [learner.py:746] ==== Starting testing data partitioner =====
2021-07-04:10:42:59,52 INFO     [divide_data.py:95] ====Initiating DataPartitioner takes 0.001184225082397461 s

2021-07-04:10:42:59,53 INFO     [learner.py:748] ==== Finished testing data partitioner =====
2021-07-04:10:42:59,56 INFO     [divide_data.py:361] ========= Start of Random Partition =========

2021-07-04:10:42:59,64 INFO     [divide_data.py:484] Raw class per worker is : array([[ 74.,  70.,  93.,  90.,  71.,  98., 112.,  61., 101., 105.,  73.,
         92.,  86.,  57.,  49., 102.,  47.,  39.,  93.,  75.,  71.,  54.,
         76.,  57., 100.,  70.,  98.,  90.,  78.,  39., 100.,  76.,  51.,
         52.,  58.]])

2021-07-04:10:42:59,65 INFO     [divide_data.py:485] ========= End of Class/Worker =========

2021-07-04:10:42:59,72 INFO     [learner.py:456] ====Worker: Start running
2021-07-04:10:42:59,367 INFO     [learner.py:494] 
Namespace(adam_epsilon=1e-08, backend='nccl', batch_size=16, bidirectional=True, blacklist_max_len=0.3, blacklist_rounds=-1, block_size=64, cache_dir=None, capacity_bin=True, clf_block_size=100, client_path='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/data/device_info/client_profile.pkl', clip_bound=0.98, clock_factor=6.092057761732853, conf_path='~/dataset/', config_name=None, cut_off_util=0.4, data_dir='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/google_speech', data_mapfile='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/google_speech/clientDataMap', data_set='google_speech', decay_epoch=15.0, decay_factor=0.95, display_step=20, do_eval=False, do_train=False, dump_epoch=1000, duplicate_data=1, enable_importance=False, enable_obs_client=True, enable_obs_importance=False, enforce_random=False, epochs=0, eval_all_checkpoints=False, eval_data_file='', eval_interval=1, eval_interval_prior=9999999, evaluate_during_training=False, exploration_alpha=0.3, exploration_decay=0.95, exploration_factor=0.9, exploration_min=0.2, filter_class=0, filter_less=17, filter_more=100000.0, finetune=False, fixed_clients=False, force_read=False, forward_pass=False, fp16=False, fp16_opt_level='O1', full_gradient_interval=20, gpu_device=0, gradient_accumulation_steps=1, gradient_policy='', hetero_allocation='1.0-1.0-1.0-1.0-1.0-1.0', heterogeneity=1.0, hidden_layers=7, hidden_size=256, input_dim=0, is_even_avg=True, job_name='google_speech', labels_path='labels.json', learners='1', learning_rate=0.04, line_by_line=False, load_epoch=1, load_model=False, load_time_stamp='0615_194942', local_rank=-1, log_path='/mnt/home/lichenni/projects/Oort/training/evals', logging_steps=500, loss_decay=0.2, malicious_clients=0, manager_port=24393, max_grad_norm=1.0, max_iter_store=100, max_steps=-1, min_learning_rate=0.0001, mlm=True, mlm_probability=0.1, model='resnet34', model_avg=True, model_name_or_path=None, model_path=None, model_size=65536, model_type='', no_cuda=False, noise_dir=None, noise_factor=0, noise_max=0.5, noise_min=0.0, noise_prob=0.4, num_class=20, num_classes=35, num_loaders=2, num_train_epochs=1.0, output_dim=0, output_dir=None, overcommit=1.1, overwrite_cache=False, overwrite_output_dir=False, pacer_delta=30.0, pacer_step=20, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, proxy_avg=False, proxy_mu=0.1, ps_ip='dev-amd20-v100', ps_port='7421', read_models_path=False, release_cache=False, resampling_interval=1, rnn_type='lstm', round_penalty=2.0, round_threshold=40.0, run_all=False, sample_mode='random', sample_rate=16000, sample_seed=233, sample_window=5.0, sampler_path=None, save_path='./', save_steps=500, save_total_limit=None, score_mode='loss', seed=42, sequential='0', server_ip='', server_port='', should_continue=False, single_sim=0, skip_partition=False, sleep_up=0, spec_augment=False, speed_volume_perturb=False, stale_threshold=0, task='speech', test_bsz=256, test_interval=20, test_manifest='data/test_manifest.csv', test_only=False, test_ratio=1.0, test_train_data=False, this_rank=1, threads=4, time_stamp='0704_104241', timeout=9999999, to_device='cuda', tokenizer_name=None, total_worker=100, train_data_file='', train_manifest='data/train_manifest.csv', upload_epoch=10, user_trace=None, validate_interval=999999, vocab_tag_size=500, vocab_token_size=10000, warmup_steps=0, weight_decay=0.0, window='hamming', window_size=0.02, window_stride=0.01, yogi_beta=0.999, yogi_beta2=-1, yogi_eta=0.005, yogi_tau=0.001, zipf_alpha='5')

====Worker: init_myprocesses
Begin!
2021-07-04:10:42:59,378 INFO     [param_server.py:491] ====Error: not enough values to unpack (expected 7, got 5), <class 'ValueError'>, param_server.py, 221
Traceback (most recent call last):
  File "/mnt/home/lichenni/projects/Oort/training/learner.py", line 767, in <module>
    run, args.backend, client_cfg)
  File "/mnt/home/lichenni/projects/Oort/training/learner.py", line 105, in init_myprocesses
    fn(rank, model, q, param_q, stop_flag, client_cfg)
  File "/mnt/home/lichenni/projects/Oort/training/learner.py", line 678, in run
    logging.info("Worker {} has completed epoch {}!".format(args.this_rank, epoch))
UnboundLocalError: local variable 'epoch' referenced before assignment
====Error: not enough values to unpack (expected 7, got 5)

Traceback (most recent call last):
  File "/mnt/home/lichenni/projects/Oort/training/param_server.py", line 540, in <module>
    q, param_q, stop_signal, run, args.backend
  File "/mnt/home/lichenni/projects/Oort/training/param_server.py", line 102, in init_myprocesses
    fn(model, queue, param_q, stop_signal, clientSampler)
  File "/mnt/home/lichenni/projects/Oort/training/param_server.py", line 214, in run
    if not queue.empty():
  File "<string>", line 2, in empty
  File "/mnt/home/lichenni/anaconda3/envs/oort/lib/python3.6/multiprocessing/managers.py", line 757, in _callmethod
    kind, result = conn.recv()
  File "/mnt/home/lichenni/anaconda3/envs/oort/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/mnt/home/lichenni/anaconda3/envs/oort/lib/python3.6/multiprocessing/connection.py", line 411, in _recv_bytes
    return self._recv(size)
  File "/mnt/home/lichenni/anaconda3/envs/oort/lib/python3.6/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
