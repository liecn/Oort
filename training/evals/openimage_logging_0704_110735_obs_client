2021-07-04:11:07:41,620 INFO     [param_server.py:12] End up with cuda device tensor([0.0610], device='cuda:0')
2021-07-04:11:07:42,84 INFO     [param_server.py:532] ====Start to initialize dataset
2021-07-04:11:07:42,85 INFO     [flLibs.py:59] ====Initialize the model
2021-07-04:11:07:51,201 INFO     [learner.py:14] End up with cuda device tensor([0.8019], device='cuda:0')
2021-07-04:11:07:51,204 INFO     [learner.py:40] ===== Experiment start on : dev-amd20-v100=====
2021-07-04:11:07:51,622 INFO     [learner.py:707] ====Start to initialize dataset
2021-07-04:11:07:51,624 INFO     [flLibs.py:59] ====Initialize the model
2021-07-04:11:07:54,233 INFO     [learner.py:730] ==== Starting training data partitioner =====
2021-07-04:11:07:54,766 INFO     [divide_data.py:95] ====Initiating DataPartitioner takes 0.5289425849914551 s

2021-07-04:11:07:54,767 INFO     [learner.py:733] ==== Finished training data partitioner =====
2021-07-04:11:08:22,879 INFO     [learner.py:87] ====Save obs_client====
2021-07-04:11:08:23,977 INFO     [param_server.py:78] ====Info of all feasible clients {'total_feasible_clients': 7903, 'total_length': 1149938}
2021-07-04:11:08:24,65 INFO     [param_server.py:139] ====PS: get in run()
2021-07-04:11:08:24,68 INFO     [learner.py:746] ==== Starting testing data partitioner =====
2021-07-04:11:08:24,148 INFO     [divide_data.py:95] ====Initiating DataPartitioner takes 0.07853126525878906 s

2021-07-04:11:08:24,148 INFO     [learner.py:748] ==== Finished testing data partitioner =====
2021-07-04:11:08:24,262 INFO     [divide_data.py:361] ========= Start of Random Partition =========

2021-07-04:11:08:24,529 INFO     [divide_data.py:484] Raw class per worker is : array([[5.3600e+03, 6.9340e+03, 6.1790e+03, 4.2030e+03, 1.3770e+03,
        1.0589e+04, 1.9490e+03, 3.3960e+03, 3.3500e+02, 3.2690e+03,
        7.5680e+03, 8.3450e+03, 4.1110e+03, 4.8400e+02, 4.9150e+03,
        6.6660e+03, 2.0680e+03, 5.2320e+03, 1.5000e+02, 8.7040e+03,
        6.6600e+02, 2.1240e+03, 3.8800e+02, 2.0350e+03, 5.8400e+02,
        1.0740e+03, 3.9700e+02, 1.7700e+02, 3.5730e+03, 2.4070e+03,
        2.5390e+03, 1.7900e+02, 2.5060e+03, 1.5240e+03, 1.3500e+03,
        2.7800e+02, 5.4600e+02, 1.0630e+03, 7.0000e+01, 6.3000e+01,
        1.7260e+03, 5.5300e+02, 3.0600e+02, 1.0000e+03, 2.5900e+02,
        3.1900e+02, 2.3390e+03, 1.9420e+03, 1.4230e+03, 9.2000e+01,
        2.3700e+02, 7.1500e+02, 3.2600e+02, 3.5470e+03, 8.0800e+02,
        1.4230e+03, 2.4800e+02, 3.4560e+03, 4.2600e+02, 3.7600e+02,
        5.1000e+01, 1.9500e+02, 6.1700e+02, 1.1510e+03, 6.5000e+02,
        4.4100e+02, 3.1700e+02, 1.2000e+02, 5.3190e+03, 8.5000e+01,
        3.8200e+02, 7.1000e+01, 1.6300e+02, 6.6000e+01, 1.8400e+02,
        2.1400e+02, 4.5000e+01, 1.0570e+03, 1.8600e+02, 6.7400e+02,
        1.9200e+02, 1.4400e+02, 8.1000e+01, 6.1000e+01, 4.6500e+02,
        2.6830e+03, 3.7700e+02, 7.6000e+01, 3.6500e+02, 2.0000e+02,
        1.5700e+02, 4.4200e+02, 5.7800e+02, 3.3500e+02, 3.6000e+02,
        2.2000e+01, 5.7300e+02, 8.8000e+01, 1.1900e+02, 8.4600e+02,
        2.6200e+02, 2.8800e+02, 1.6700e+02, 6.8000e+01, 6.1000e+01,
        4.3500e+02, 1.3500e+02, 1.3400e+02, 5.2900e+02, 2.7600e+02,
        1.0600e+02, 2.2900e+02, 1.2100e+02, 4.2000e+01, 1.4100e+02,
        4.8400e+02, 6.4000e+01, 2.4000e+01, 3.6100e+02, 4.0300e+02,
        2.8000e+01, 1.5100e+02, 1.1700e+02, 2.0000e+00, 3.9600e+02,
        1.4700e+02, 6.9000e+01, 1.2300e+02, 1.7800e+02, 5.9000e+01,
        1.9100e+02, 1.4900e+02, 2.6300e+02, 7.5000e+01, 1.6600e+02,
        2.4200e+02, 1.8900e+02, 5.3000e+01, 3.1500e+02, 4.0000e+01,
        6.3000e+01, 8.8000e+01, 1.6500e+02, 1.8600e+02, 5.0000e+01,
        1.1400e+02, 2.1800e+02, 3.5200e+02, 8.0000e+01, 6.6000e+01,
        2.2500e+02, 1.7200e+02, 2.0300e+02, 4.9000e+01, 5.8000e+01,
        1.5000e+02, 2.0400e+02, 4.1000e+01, 1.9000e+02, 1.0600e+02,
        1.2600e+02, 5.6000e+01, 5.3000e+01, 1.1100e+02, 1.0900e+02,
        4.2200e+02, 2.2300e+02, 3.6000e+01, 6.2000e+01, 2.2300e+02,
        2.7600e+02, 1.9100e+02, 2.0000e+02, 3.3000e+02, 2.6000e+01,
        5.2000e+01, 1.1600e+02, 6.2000e+01, 1.6500e+02, 9.7000e+01,
        1.1800e+02, 1.6200e+02, 1.4300e+02, 3.8000e+01, 8.4000e+01,
        1.4700e+02, 1.5500e+02, 1.8200e+02, 7.3000e+01, 1.3900e+02,
        7.0000e+01, 1.0300e+02, 8.2000e+01, 5.7000e+01, 4.2000e+01,
        1.8000e+02, 7.7000e+01, 9.7000e+01, 8.1000e+01, 9.9000e+01,
        2.0000e+01, 1.9300e+02, 8.9000e+01, 1.7000e+01, 1.9000e+01,
        8.7000e+01, 7.5000e+01, 3.0400e+02, 6.2000e+01, 2.5300e+02,
        9.2000e+01, 1.2300e+02, 9.2000e+01, 9.5000e+01, 4.1000e+01,
        1.7900e+02, 5.0000e+01, 1.7000e+02, 1.1800e+02, 1.5000e+01,
        4.7000e+01, 1.8100e+02, 5.1000e+01, 1.1100e+02, 4.9000e+01,
        3.2000e+01, 8.3000e+01, 4.3000e+01, 1.6100e+02, 5.2000e+01,
        6.5000e+01, 9.1000e+01, 8.8000e+01, 6.3000e+01, 6.5000e+01,
        7.4000e+01, 6.2000e+01, 1.2700e+02, 1.2100e+02, 1.0200e+02,
        1.6100e+02, 2.7000e+01, 1.3200e+02, 1.0800e+02, 5.7000e+01,
        8.6000e+01, 1.0600e+02, 6.1000e+01, 7.2000e+01, 2.3700e+02,
        5.5000e+01, 3.6000e+01, 1.3300e+02, 3.4000e+01, 1.3800e+02,
        5.3000e+01, 1.7000e+01, 5.9000e+01, 4.0000e+01, 5.3000e+01,
        9.1000e+01, 6.7000e+01, 1.1800e+02, 6.9000e+01, 4.4000e+01,
        7.0000e+01, 9.0000e+00, 5.8000e+01, 9.1000e+01, 5.0000e+01,
        3.8000e+01, 1.6800e+02, 6.6000e+01, 2.8000e+01, 9.6000e+01,
        8.5000e+01, 4.4000e+01, 1.2900e+02, 3.2000e+01, 3.7000e+01,
        1.6300e+02, 1.1900e+02, 3.8000e+01, 8.5000e+01, 4.9000e+01,
        3.1000e+01, 9.0000e+00, 1.0000e+01, 1.8800e+02, 8.3000e+01,
        5.5000e+01, 9.7000e+01, 4.8000e+01, 3.9000e+01, 7.6000e+01,
        7.0000e+00, 1.6100e+02, 9.5000e+01, 6.0000e+00, 1.1500e+02,
        3.7000e+01, 4.8000e+01, 6.7000e+01, 2.0000e+01, 4.5000e+01,
        6.2000e+01, 5.0000e+01, 4.7000e+01, 5.3000e+01, 3.6000e+01,
        3.4000e+01, 4.1000e+01, 4.4000e+01, 9.0000e+01, 4.3000e+01,
        6.0000e+01, 1.5200e+02, 7.8000e+01, 3.2400e+02, 3.7000e+01,
        7.1000e+01, 3.8000e+01, 9.4000e+01, 1.1000e+01, 7.2000e+01,
        5.9000e+01, 3.0000e+01, 4.7000e+01, 1.2500e+02, 1.0600e+02,
        5.5000e+01, 8.0000e+01, 4.7000e+01, 7.1000e+01, 6.8000e+01,
        3.9000e+01, 4.3000e+01, 2.4000e+01, 4.3000e+01, 3.6000e+01,
        8.9000e+01, 3.8000e+01, 1.0300e+02, 2.6000e+01, 6.7000e+01,
        2.8000e+01, 5.0000e+00, 8.4000e+01, 1.4000e+01, 4.0000e+01,
        3.6000e+01, 1.1900e+02, 4.3000e+01, 8.5000e+01, 1.0100e+02,
        4.2000e+01, 5.0000e+00, 9.0000e+00, 3.0000e+01, 9.7000e+01,
        9.0000e+00, 3.6000e+01, 2.6000e+01, 9.7000e+01, 6.0000e+01,
        1.4600e+02, 6.0000e+01, 2.3000e+01, 3.8000e+01, 3.9000e+01,
        3.5000e+01, 7.1000e+01, 5.2000e+01, 2.5000e+01, 1.8000e+01,
        4.9000e+01, 4.3000e+01, 2.6000e+01, 2.1000e+01, 2.4000e+01,
        2.5000e+01, 3.4000e+01, 3.9000e+01, 2.6000e+01, 1.5400e+02,
        5.2000e+01, 2.2000e+01, 3.6000e+01, 5.3000e+01, 6.0000e+00,
        3.6000e+01, 4.4000e+01, 9.0000e+00, 1.4000e+01, 3.8000e+01,
        3.0000e+00, 1.0000e+01, 2.8000e+01, 5.0000e+01, 2.8000e+01,
        2.0000e+00, 1.8000e+01, 5.8000e+01, 3.3000e+01, 1.5000e+01,
        3.5000e+01, 4.0000e+01, 1.7000e+01, 1.4000e+01, 3.6000e+01,
        1.5200e+02, 6.0000e+01, 1.2000e+01, 2.0000e+00, 3.3000e+01,
        3.4000e+01, 9.7000e+01, 3.4000e+01, 1.4000e+01, 1.6000e+01,
        8.4000e+01, 2.7000e+01, 5.5000e+01, 4.3000e+01, 1.6000e+01,
        2.8000e+01, 6.0000e+00, 8.9000e+01, 2.8000e+01, 4.8000e+01,
        4.0000e+01, 4.0000e+01, 3.8000e+01, 4.1000e+01, 3.9000e+01,
        4.2000e+01, 8.0000e+00, 3.0000e+01, 5.3000e+01, 5.0000e+00,
        3.0000e+00, 2.2000e+01, 3.4000e+01, 8.0000e+00, 4.1000e+01,
        2.6000e+01, 9.0000e+00, 3.3000e+01, 6.3000e+01, 4.0000e+01,
        1.1000e+01, 1.3000e+01, 9.3000e+01, 3.1000e+01, 9.0000e+00,
        3.5000e+01, 3.0000e+00, 4.5000e+01, 4.5000e+01, 4.0000e+00,
        1.6000e+01, 3.8000e+01, 1.3000e+01, 9.0000e+00, 4.8000e+01,
        5.7000e+01, 4.0000e+00, 2.0000e+01, 3.9000e+01, 4.7000e+01,
        2.1000e+01, 0.0000e+00, 1.8000e+01, 1.0000e+00, 8.7000e+01,
        2.3000e+01, 1.9000e+01, 1.3000e+01, 4.0000e+01, 3.5000e+01,
        4.3000e+01, 6.3000e+01, 3.1000e+01, 3.5000e+01, 5.2000e+01,
        3.4000e+01, 1.0000e+00, 1.7000e+01, 2.0000e+00, 1.0000e+01,
        1.4000e+01, 3.0000e+01, 4.4000e+01, 1.6000e+01, 1.0000e+00,
        2.4000e+01, 3.6000e+01, 3.3000e+01, 3.6000e+01, 5.5000e+01,
        4.1000e+01, 1.0000e+00, 3.9000e+01, 1.0000e+01, 1.0000e+00,
        2.0000e+00, 9.0000e+00, 1.8000e+01, 9.0000e+00, 2.8000e+01,
        2.0000e+00, 8.0000e+00, 2.9000e+01, 7.1000e+01, 2.3000e+01,
        6.0000e+00, 0.0000e+00, 4.4000e+01, 1.3000e+01, 0.0000e+00,
        1.3000e+01, 1.8000e+01, 9.0000e+00, 1.5000e+01, 4.0000e+00,
        2.5000e+01, 2.0000e+00, 7.7000e+01, 4.8000e+01, 1.2000e+01,
        2.0000e+00, 0.0000e+00, 6.0000e+00, 1.7000e+01, 6.0000e+00,
        2.1000e+01, 6.4000e+01, 0.0000e+00, 1.0000e+00, 3.0000e+00,
        2.4000e+01, 1.3000e+01, 8.0000e+00, 5.0000e+00, 6.0000e+00,
        1.6000e+01, 5.0000e+00, 4.1000e+01, 4.3000e+01, 2.0000e+00,
        3.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 1.6000e+01,
        6.0000e+00, 3.0000e+00, 5.0000e+00, 4.4000e+01, 1.0000e+01,
        1.0000e+00, 1.4300e+02, 0.0000e+00, 0.0000e+00, 4.0000e+00,
        6.0000e+00, 3.0000e+00, 5.0000e+00, 4.0000e+00, 1.7000e+01,
        2.0000e+00, 5.1000e+01, 0.0000e+00, 3.0000e+00, 0.0000e+00,
        1.9000e+01, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,
        1.1000e+01, 1.0000e+01, 0.0000e+00, 9.0000e+00, 6.0000e+00,
        4.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00, 9.0000e+00,
        7.0000e+00, 3.2000e+01, 0.0000e+00, 0.0000e+00, 1.0000e+00,
        0.0000e+00]])

2021-07-04:11:08:24,533 INFO     [divide_data.py:485] ========= End of Class/Worker =========

2021-07-04:11:08:24,625 INFO     [learner.py:456] ====Worker: Start running
2021-07-04:11:08:25,459 INFO     [learner.py:494] 
Namespace(adam_epsilon=1e-08, backend='nccl', batch_size=32, bidirectional=True, blacklist_max_len=0.3, blacklist_rounds=-1, block_size=64, cache_dir=None, capacity_bin=True, clf_block_size=100, client_path='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/data/device_info/client_profile.pkl', clip_bound=0.98, clock_factor=2.906137184115524, conf_path='~/dataset/', config_name=None, cut_off_util=0.7, data_dir='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/open_images', data_mapfile='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/open_images/clientDataMap', data_set='openImg', decay_epoch=5, decay_factor=0.95, display_step=20, do_eval=False, do_train=False, dump_epoch=1000, duplicate_data=1, enable_importance=False, enable_obs_client=True, enable_obs_importance=False, enforce_random=False, epochs=0, eval_all_checkpoints=False, eval_data_file='', eval_interval=5, eval_interval_prior=9999999, evaluate_during_training=False, exploration_alpha=0.3, exploration_decay=0.95, exploration_factor=0.9, exploration_min=0.2, filter_class=0, filter_less=33, filter_more=100000.0, finetune=False, fixed_clients=False, force_read=False, forward_pass=False, fp16=False, fp16_opt_level='O1', full_gradient_interval=20, gpu_device=0, gradient_accumulation_steps=1, gradient_policy='yogi', hetero_allocation='1.0-1.0-1.0-1.0-1.0-1.0', heterogeneity=1.0, hidden_layers=7, hidden_size=256, input_dim=0, is_even_avg=True, job_name='openimage', labels_path='labels.json', learners='1', learning_rate=0.04, line_by_line=False, load_epoch=1, load_model=False, load_time_stamp='0615_194942', local_rank=-1, log_path='/mnt/home/lichenni/projects/Oort/training/evals', logging_steps=500, loss_decay=0.2, malicious_clients=0, manager_port=32081, max_grad_norm=1.0, max_iter_store=100, max_steps=-1, min_learning_rate=0.0001, mlm=True, mlm_probability=0.1, model='shufflenet_v2_x2_0', model_avg=True, model_name_or_path=None, model_path=None, model_size=65536, model_type='', no_cuda=False, noise_dir=None, noise_factor=0, noise_max=0.5, noise_min=0.0, noise_prob=0.4, num_class=596, num_classes=35, num_loaders=2, num_train_epochs=1.0, output_dim=0, output_dir=None, overcommit=1.1, overwrite_cache=False, overwrite_output_dir=False, pacer_delta=10.0, pacer_step=20, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, proxy_avg=False, proxy_mu=0.1, ps_ip='dev-amd20-v100', ps_port='50325', read_models_path=False, release_cache=False, resampling_interval=1, rnn_type='lstm', round_penalty=2.0, round_threshold=10, run_all=False, sample_mode='random', sample_rate=16000, sample_seed=233, sample_window=5.0, sampler_path=None, save_path='./', save_steps=500, save_total_limit=None, score_mode='loss', seed=42, sequential='0', server_ip='', server_port='', should_continue=False, single_sim=0, skip_partition=False, sleep_up=0, spec_augment=False, speed_volume_perturb=False, stale_threshold=0, task='cv', test_bsz=256, test_interval=20, test_manifest='data/test_manifest.csv', test_only=False, test_ratio=1.0, test_train_data=False, this_rank=1, threads=4, time_stamp='0704_110735', timeout=9999999, to_device='cuda', tokenizer_name=None, total_worker=60000, train_data_file='', train_manifest='data/train_manifest.csv', upload_epoch=10, user_trace=None, validate_interval=999999, vocab_tag_size=500, vocab_token_size=10000, warmup_steps=0, weight_decay=0.0, window='hamming', window_size=0.02, window_stride=0.01, yogi_beta=0.999, yogi_beta2=-1, yogi_eta=0.005, yogi_tau=0.001, zipf_alpha='5')

2.105802536010742
0.26523542404174805
====Worker: init_myprocesses
Begin!
2021-07-04:11:08:25,469 INFO     [param_server.py:491] ====Error: not enough values to unpack (expected 7, got 5), <class 'ValueError'>, param_server.py, 221
Traceback (most recent call last):
  File "/mnt/home/lichenni/projects/Oort/training/learner.py", line 767, in <module>
    run, args.backend, client_cfg)
  File "/mnt/home/lichenni/projects/Oort/training/learner.py", line 105, in init_myprocesses
    fn(rank, model, q, param_q, stop_flag, client_cfg)
  File "/mnt/home/lichenni/projects/Oort/training/learner.py", line 678, in run
    logging.info("Worker {} has completed epoch {}!".format(args.this_rank, epoch))
UnboundLocalError: local variable 'epoch' referenced before assignment
====Error: not enough values to unpack (expected 7, got 5)

Traceback (most recent call last):
  File "/mnt/home/lichenni/projects/Oort/training/param_server.py", line 540, in <module>
    q, param_q, stop_signal, run, args.backend
  File "/mnt/home/lichenni/projects/Oort/training/param_server.py", line 102, in init_myprocesses
    fn(model, queue, param_q, stop_signal, clientSampler)
  File "/mnt/home/lichenni/projects/Oort/training/param_server.py", line 214, in run
    if not queue.empty():
  File "<string>", line 2, in empty
  File "/mnt/home/lichenni/anaconda3/envs/oort/lib/python3.6/multiprocessing/managers.py", line 756, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/mnt/home/lichenni/anaconda3/envs/oort/lib/python3.6/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/mnt/home/lichenni/anaconda3/envs/oort/lib/python3.6/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
  File "/mnt/home/lichenni/anaconda3/envs/oort/lib/python3.6/multiprocessing/reduction.py", line 40, in __init__
    self.dispatch_table = self._copyreg_dispatch_table.copy()
KeyboardInterrupt
